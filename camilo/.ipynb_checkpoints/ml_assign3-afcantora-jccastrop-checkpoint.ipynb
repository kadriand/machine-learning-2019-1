{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Assignment 3</h1>\n",
    "<h3>Juan Camilo Castro Pinto</h3>\n",
    "<h3>Andres Felipe Cantor</h3>\n",
    "<br/>\n",
    "\n",
    "### 1.\n",
    "#### (a)\n",
    "\n",
    "let $ x = \\{x_{1}, . . . , x_{n} \\} $ be a subset of a input data set X. Consider a kernel function $$\\it{k} : X \\times X   \\rightarrow \\Re $$ $$ X \\rightarrow \\phi(X)$$\n",
    "\n",
    "Then the average distance to the enter of mass of the image of set x in the feature space is: $$\\frac{1}{n}\\sum_{i=1}^{n}\\lVert\\phi(x_{i})-\\phi_{S}(x)\\rVert$$\n",
    "\n",
    "With $$\\phi_{S}(x) = \\frac{1}{n}\\sum_{i=1}^{n}\\phi(x_{i})$$\n",
    "\n",
    "So taking the definition of $\\lVert x\\rVert$ as $\\sqrt{\\langle x,x \\rangle}$ (not squared). Then we can rewrite $\\lVert\\phi(x_{i})-\\phi_{S}(x)\\rVert$ as \n",
    "\n",
    "$$\\sqrt{\\langle \\phi(x_{i})-\\phi_{S}(x),\\phi(x_{i})-\\phi_{S}(x) \\rangle}$$ By distributive property of dot product\n",
    "\n",
    "$$\\sqrt{\\langle \\phi(x_{i}),\\phi(x_{i}) \\rangle - \\langle \\phi(x_{i}),\\phi_S(x) \\rangle - \\langle \\phi_{S}(x),\\phi(x_{i})\\rangle + \\langle \\phi(x),\\phi_S(x) \\rangle} $$ \n",
    "\n",
    "By commutative property\n",
    "\n",
    "$$\\sqrt{\\langle \\phi(x_{i}),\\phi(x_{i}) \\rangle - 2\\langle \\phi(x_{i}),\\phi_S(x) \\rangle + \\langle \\phi_S(x),\\phi_S(x) \\rangle} $$ \n",
    "\n",
    "Replacing the definition of $\\phi_S(x)$ we have\n",
    "\n",
    "$$\\sqrt{\\langle \\phi(x_{i}),\\phi(x_{i}) \\rangle - 2\\langle \\phi(x_{i}),\\frac{1}{n}\\sum_{j=1}^{n}\\phi(x_{j}) \\rangle + \\langle \\frac{1}{n}\\sum_{j=1}^{n}\\phi(x_{j}),\\frac{1}{n}\\sum_{j=1}^{n}\\phi(x_{j}) \\rangle}$$ \n",
    "\n",
    "Taking out the scalars, we have\n",
    "\n",
    "$$\\sqrt{\\langle \\phi(x_{i}),\\phi(x_{i}) \\rangle - \\frac{2}{n}\\langle \\phi(x_{i}),\\sum_{j=1}^{n}\\phi(x_{j}) \\rangle + \\frac{1}{n^2}\\langle \\sum_{j=1}^{n}\\phi(x_{j}),\\sum_{k=1}^{n}\\phi(x_{k}) \\rangle}$$ \n",
    "\n",
    "By the distributive property of dot product\n",
    "\n",
    "$$\\sqrt{\\langle \\phi(x_{i}),\\phi(x_{i}) \\rangle - \\frac{2}{n} \\sum_{j=1}^{n} \\langle \\phi(x_{i}), \\phi(x_{j}) \\rangle + \\frac{1}{n^2} \\sum_{j=1}^n\\sum_{k=1}^n \\langle \\phi(x_{j}),\\phi(x_{k}) \\rangle}$$\n",
    "\n",
    "Taking into account that $K(x_{i},x_{j}) = \\langle x_{i},x_{j} \\rangle$ we can rewrite the result as:\n",
    "\n",
    "$$\\sqrt{K(x_{i},x_{i}) - \\frac{2}{n} \\sum_{j=1}^{n} K(x_{i},x_{j}) + \\frac{1}{n^2} \\sum_{j=1}^n\\sum_{k=1}^n K(x_{j},x_{k})}$$\n",
    "\n",
    "Finally, we can express the average distance to the center of mass as:\n",
    "\n",
    "$$\\frac{1}{n}\\sum_{i=1}^{n}\\sqrt{K(x_{i},x_{i}) - \\frac{2}{n} \\sum_{j=1}^{n} K(x_{i},x_{j}) + \\frac{1}{n^2} \\sum_{j=1}^n\\sum_{k=1}^n K(x_{j},x_{k})}$$\n",
    "\n",
    "#### (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-da3edab4ebc7>, line 41)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-da3edab4ebc7>\"\u001b[1;36m, line \u001b[1;32m41\u001b[0m\n\u001b[1;33m    print \"i.   \", average_to_center_mass(x,0) , \"\\n\"\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([[0,1],[-1,3],[2,4],[3,-1],[-1,-2]])\n",
    "\n",
    "def kernel(x , y, ind):\n",
    "    if ind == 0:\n",
    "        return np.dot(x,y)\n",
    "    elif ind == 1:\n",
    "        return np.power(np.dot(x,y),2)\n",
    "    elif ind == 2:\n",
    "        return np.power(np.dot(x,y) + 1,5)\n",
    "    elif ind == 3:\n",
    "        return np.exp(-np.dot(x-y,x-y)/ 2.0)\n",
    "    \n",
    "def average_to_center_mass(x, ind):   \n",
    "    n = x.shape[0]\n",
    "    gram_matrix = np.zeros(shape=(n,n))    \n",
    "    gram_sum = 0.0\n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            gram_matrix[i][j] = gram_matrix[j][i] = kernel(x[i],x[j], ind)\n",
    "            if i == j:\n",
    "                gram_sum += gram_matrix[i][j]\n",
    "            else:\n",
    "                gram_sum += 2*gram_matrix[i][j]\n",
    "    \n",
    "    #print gram_matrix\n",
    "    #print gram_sum\n",
    "    result = 0.0\n",
    "    for i in range(n):\n",
    "        aux = gram_matrix[i][i]\n",
    "        aux2 = 0\n",
    "        for j in range(n):\n",
    "            aux2 += gram_matrix[i][j]\n",
    "        aux -= (2.0/n) * aux2\n",
    "        aux += (1.0/np.power(n,2))*gram_sum        \n",
    "        result += np.sqrt(aux)\n",
    "        \n",
    "    return (1.0/n)*result\n",
    "        \n",
    "print \"i.   \", average_to_center_mass(x,0) , \"\\n\"\n",
    "print \"ii.  \", average_to_center_mass(x,1) , \"\\n\"\n",
    "print \"iii. \", average_to_center_mass(x,2) , \"\\n\"\n",
    "print \"iv.  \", average_to_center_mass(x,3) , \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.\n",
    "#### (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function fetch_mldata is deprecated; fetch_mldata was deprecated in version 0.20 and will be removed in version 0.22\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "c:\\python37\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function mldata_filename is deprecated; mldata_filename was deprecated in version 0.20 and will be removed in version 0.22\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Download the MNIST digit recognition database:\n",
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize the features using preprocessing function of sklearn\n",
    "from sklearn import preprocessing\n",
    "normalized_data = preprocessing.scale(mnist.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c)\n",
    "For the training we used 70% of samples, and 30% for testing. Also we chose the class 6 and 9 to do the excercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "global_train_data = {}\n",
    "global_test_data = {}\n",
    "\n",
    "#Get data for each label\n",
    "for i in range(0,10):\n",
    "    indexes = np.argwhere(mnist.target == i)\n",
    "    n,m = indexes.shape\n",
    "    train_limit = int(n*0.7)    \n",
    "    aux = normalized_data[indexes]\n",
    "    n,l,m = aux.shape\n",
    "    aux = aux.reshape((n, m))\n",
    "    global_train_data[i] = aux[0:train_limit, :]\n",
    "    global_test_data[i] = aux[train_limit:n, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print('Optimum is ', C_optim)? (<ipython-input-2-3ae8fbc3e968>, line 34)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-3ae8fbc3e968>\"\u001b[1;36m, line \u001b[1;32m34\u001b[0m\n\u001b[1;33m    print 'Optimum is ', C_optim\u001b[0m\n\u001b[1;37m                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print('Optimum is ', C_optim)?\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Define a function to train differents Lineal SVM changing the C parameter\n",
    "def classifier(train_data, train_target, test_data, test_target, Cs):\n",
    "    linearSVM = LinearSVC()    \n",
    "    train_errors = list()\n",
    "    test_errors = list()\n",
    "    for C in Cs:\n",
    "        linearSVM.set_params(C=C)    \n",
    "        linearSVM.fit(train_data, train_target) \n",
    "        train_errors.append(1.0 - linearSVM.score(train_data, train_target))\n",
    "        test_errors.append(1.0 - linearSVM.score(test_data, test_target))\n",
    "    \n",
    "    return train_errors, test_errors\n",
    "\n",
    "\n",
    "Cs = np.logspace(-15.0, 15.0, num=31, base=2.0)\n",
    "\n",
    "#Select train data of class 6 and 9\n",
    "train_data = np.vstack((global_train_data[6], global_train_data[9]))\n",
    "train_target = np.hstack((np.ones((global_train_data[6].shape[0])), -1*np.ones((global_train_data[9].shape[0]))))\n",
    "\n",
    "#Select test data of class 6 and 9\n",
    "test_data = np.vstack((global_test_data[6], global_test_data[9]))\n",
    "test_target = np.hstack((np.ones((global_test_data[6].shape[0])), -1*np.ones((global_test_data[9].shape[0]))))\n",
    "\n",
    "train_errors, test_errors = classifier(train_data, train_target, test_data, test_target, Cs)\n",
    "\n",
    "i_C_optim_test = np.argwhere(test_errors == np.min(test_errors))\n",
    "i_C_optim_train = np.argwhere(train_errors == np.min(train_errors))\n",
    "C_optim = Cs[i_C_optim_test[-2,0]]\n",
    "\n",
    "print 'Optimum is ', C_optim\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.semilogx(Cs, train_errors, label='Train', basex=2.0)\n",
    "plt.semilogx(Cs, test_errors, label='Test', basex=2.0)\n",
    "plt.vlines(C_optim, plt.ylim()[0], np.max(test_errors), color='k',\n",
    "           linewidth=3, label='Optimum on train and test')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.xlabel('Regularization parameter')\n",
    "plt.ylabel('Error')\n",
    "plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $C=2^{-4}$ and $C=2^{-3}$ train and test errors are minimal. After that it seems that the classifier is overfitting to the training samples. Also the behavior of errors is as expected, because when C is too small the error has a little weight in the classifier. When C increases the error matter more and more, therefore the clasification is better. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get a linearSVM with the optimal C, and then get the weights.\n",
    "linearSVM = LinearSVC()\n",
    "linearSVM.set_params(C=C_optim)    \n",
    "linearSVM.fit(train_data, train_target)\n",
    "weights = linearSVM.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (e)\n",
    "We used $C=2^{-4}$ as optimum parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as cls\n",
    "#Reshape\n",
    "shape_matrix = weights.reshape((28,28))\n",
    "plt.title('Weigths')\n",
    "plt.imshow(shape_matrix, vmin=-0.1, vmax=0.1, cmap=plt.get_cmap('coolwarm'))\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.title('Sample of 6')\n",
    "plt.imshow(global_train_data[6][500].reshape((28,28)), cmap=plt.get_cmap('binary'))\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.title('Sample of 9')\n",
    "plt.imshow(global_train_data[9][1500].reshape((28,28)), cmap=plt.get_cmap('binary'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights' plot shows the importance of the feature when samples are classified. When the weight is zero, the color is gray, when positive is red and negative is blue. Around the image, you can see that the color is gray, that means, the features in those places doesn't matter in the calssification. But places where is more positive (deep red) are related with the features that can identify a six. The same happens when the value is negative (deep blue), it seems that is possible to identify a nine. With the sample 6 and 9, that is showed below of the weights' plot, is possible to compare and get that conclussion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (f)\n",
    "##### i.) Pair (0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as cls\n",
    "#Select train data of class 0 and 1\n",
    "train_data = np.vstack((global_train_data[0], global_train_data[1]))\n",
    "train_target = np.hstack((np.ones((global_train_data[0].shape[0])), -1*np.ones((global_train_data[1].shape[0]))))\n",
    "\n",
    "#Select test data of class 0 and 1\n",
    "test_data = np.vstack((global_test_data[0], global_test_data[1]))\n",
    "test_target = np.hstack((np.ones((global_test_data[0].shape[0])), -1*np.ones((global_test_data[1].shape[0]))))\n",
    "\n",
    "train_errors, test_errors = classifier(train_data, train_target, test_data, test_target, Cs)\n",
    "\n",
    "i_C_optim_test = np.argwhere(test_errors == np.min(test_errors))\n",
    "i_C_optim_train = np.argwhere(train_errors == np.min(train_errors))\n",
    "C_optim = Cs[i_C_optim_test[-1,0]]\n",
    "\n",
    "print 'Optimum is ', C_optim\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.semilogx(Cs, train_errors, label='Train', basex=2.0)\n",
    "plt.semilogx(Cs, test_errors, label='Test', basex=2.0)\n",
    "plt.vlines(C_optim, plt.ylim()[0], np.max(test_errors), color='k',\n",
    "           linewidth=3, label='Optimum on train and test')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.xlabel('Regularization parameter')\n",
    "plt.ylabel('Error')\n",
    "plt.show()\n",
    "\n",
    "linearSVM.set_params(C=C_optim)    \n",
    "linearSVM.fit(train_data, train_target)\n",
    "shape_matrix = linearSVM.coef_.reshape((28,28))\n",
    "plt.title('Weigths')\n",
    "plt.imshow(shape_matrix,vmin=-0.1, vmax=0.1, cmap=plt.get_cmap('coolwarm'))\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.title('Sample of 0')\n",
    "plt.imshow(global_train_data[0][500].reshape((28,28)), cmap=plt.get_cmap('binary'))\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.title('Sample of 1')\n",
    "plt.imshow(global_train_data[1][1500].reshape((28,28)), cmap=plt.get_cmap('binary'))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the pair (0,1) we can see that the results are good. The train error goes to zero and the test error is too close to zero. Like the pair (6,9) the test error increases after the optimum C, that happens because the classifier is overfitting. The weights' plot show that the center of image is important to classify 1 and around to classify 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ii.) Pair (2,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select train data of class 2 and 7\n",
    "train_data = np.vstack((global_train_data[2], global_train_data[7]))\n",
    "train_target = np.hstack((np.ones((global_train_data[2].shape[0])), -1*np.ones((global_train_data[7].shape[0]))))\n",
    "\n",
    "#Select test data of class 2 and 7\n",
    "test_data = np.vstack((global_test_data[2], global_test_data[7]))\n",
    "test_target = np.hstack((np.ones((global_test_data[2].shape[0])), -1*np.ones((global_test_data[7].shape[0]))))\n",
    "\n",
    "train_errors, test_errors = classifier(train_data, train_target, test_data, test_target, Cs)\n",
    "\n",
    "i_C_optim_test = np.argwhere(test_errors == np.min(test_errors))\n",
    "i_C_optim_train = np.argwhere(train_errors == np.min(train_errors))\n",
    "C_test_optim = Cs[i_C_optim_test[-1,0]]\n",
    "C_train_optim = Cs[i_C_optim_train[0,0]]\n",
    "\n",
    "print 'Optimum on test is ', C_test_optim\n",
    "print 'Optimum on train is ', C_train_optim\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.semilogx(Cs, train_errors, label='Train', basex=2.0)\n",
    "plt.semilogx(Cs, test_errors, label='Test', basex=2.0)\n",
    "plt.vlines(C_test_optim, plt.ylim()[0], np.max(test_errors), color='k',\n",
    "           linewidth=3, label='Optimum on test')\n",
    "plt.vlines(C_train_optim, plt.ylim()[0], np.max(test_errors), color='g',\n",
    "           linewidth=3, label='Optimum on train')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.xlabel('Regularization parameter')\n",
    "plt.ylabel('Error')\n",
    "plt.show()\n",
    "\n",
    "linearSVM.set_params(C=C_test_optim)    \n",
    "linearSVM.fit(train_data, train_target)\n",
    "shape_matrix = linearSVM.coef_.reshape((28,28))\n",
    "plt.title('Weigths with test optimum')\n",
    "plt.imshow(shape_matrix,vmin=-0.1, vmax=0.1, cmap=plt.get_cmap('coolwarm'))\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.title('Sample of 2')\n",
    "plt.imshow(global_train_data[2][500].reshape((28,28)), cmap=plt.get_cmap('binary'))\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.title('Sample of 7')\n",
    "plt.imshow(global_train_data[7][1500].reshape((28,28)), cmap=plt.get_cmap('binary'))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case (2,7) we have two optimum. One is the train optimum $C=2^{-7}$, the other is the test optimum $C=2^{-1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### iii.) Pair (3,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select train data of class 3 and 8\n",
    "train_data = np.vstack((global_train_data[3], global_train_data[8]))\n",
    "train_target = np.hstack((np.ones((global_train_data[3].shape[0])), -1*np.ones((global_train_data[8].shape[0]))))\n",
    "\n",
    "#Select test data of class 3 and 8\n",
    "test_data = np.vstack((global_test_data[3], global_test_data[8]))\n",
    "test_target = np.hstack((np.ones((global_test_data[3].shape[0])), -1*np.ones((global_test_data[8].shape[0]))))\n",
    "\n",
    "train_errors, test_errors = classifier(train_data, train_target, test_data, test_target, Cs)\n",
    "\n",
    "i_C_optim_test = np.argwhere(test_errors == np.min(test_errors))\n",
    "i_C_optim_train = np.argwhere(train_errors == np.min(train_errors))\n",
    "C_test_optim = Cs[i_C_optim_test[-1,0]]\n",
    "C_train_optim = Cs[i_C_optim_train[0,0]]\n",
    "\n",
    "print 'Optimum on test is ', C_test_optim\n",
    "print 'Optimum on train is ', C_train_optim\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.semilogx(Cs, train_errors, label='Train', basex=2.0)\n",
    "plt.semilogx(Cs, test_errors, label='Test', basex=2.0)\n",
    "plt.vlines(C_test_optim, plt.ylim()[0], np.max(test_errors), color='k',\n",
    "           linewidth=3, label='Optimum on test')\n",
    "plt.vlines(C_train_optim, plt.ylim()[0], np.max(test_errors), color='g',\n",
    "           linewidth=3, label='Optimum on train')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.xlabel('Regularization parameter')\n",
    "plt.ylabel('Error')\n",
    "plt.show()\n",
    "\n",
    "linearSVM.set_params(C=C_test_optim)    \n",
    "linearSVM.fit(train_data, train_target)\n",
    "shape_matrix = linearSVM.coef_.reshape((28,28))\n",
    "plt.title('Weigths with test optimum')\n",
    "plt.imshow(shape_matrix,vmin=-0.1, vmax=0.1, cmap=plt.get_cmap('coolwarm'))\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.title('Sample of 3')\n",
    "plt.imshow(global_train_data[3][500].reshape((28,28)), cmap=plt.get_cmap('binary'))\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.title('Sample of 8')\n",
    "plt.imshow(global_train_data[8][1500].reshape((28,28)), cmap=plt.get_cmap('binary'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case (3,8), there is not a linear SVM that classifies the total of training samples. If we compare 3 and 8, they are similar, then the classifier has some errors in its classification. Also we can see, when the C Parameter increases the train error increase too, this behavior doesn't appear with the before studied pairs. That could happen because the classifier has more weight in the error and how I said before, a linear SVM doesn't work good in this case, then the error is going to increase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3\n",
    "#### (a)\n",
    "\n",
    "English Samples were taken from: https://en.wiktionary.org/wiki/Wiktionary:Frequency_lists/Contemporary_fiction <br>\n",
    "Spanish Samples were taken from: https://s3.amazonaws.com/101languages/common-words/spanish.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import datetime\n",
    "\n",
    "file = open(\"english_dataset.txt\", \"r\") \n",
    "eng = filter(bool, file.read().split(\" \"))\n",
    "print len(eng)\n",
    "\n",
    "file = open(\"spanish_dataset.txt\", \"r\") \n",
    "esp = filter(bool, file.read().split(\" \"))\n",
    "print len(esp)\n",
    "\n",
    "#first we need to build the train data and the target classes\n",
    "#target classes: 0 = english , 1 = spanish\n",
    "#train data: we will select the first 'sample_size' samples of the gathered datasets and combine them\n",
    "sample_size = 1000\n",
    "prod_size = 500\n",
    "\n",
    "eng_train = eng[:sample_size]\n",
    "esp_train = esp[:sample_size]\n",
    "train = eng_train + esp_train\n",
    "\n",
    "eng_target = np.zeros(sample_size)\n",
    "esp_target = np.ones(sample_size)\n",
    "target = np.append(eng_target,esp_target)\n",
    "\n",
    "#then we create the production test dataset from the remaining data\n",
    "prod_eng = eng[sample_size+1:sample_size+prod_size+1]\n",
    "prod_esp = esp[sample_size+1:sample_size+prod_size+1]\n",
    "prod = prod_eng + prod_esp\n",
    "\n",
    "true_eng = np.zeros(prod_size)\n",
    "true_esp = np.ones(prod_size)\n",
    "true = np.append(true_eng, true_esp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b)\n",
    "\n",
    "We used the implementation of $n-grams$ and $SSK$ from [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n-grams kernel(NGK) implementation copied from: https://github.com/muggin/string-kernels/blob/master/src/ngk_kernel.py\n",
    "\n",
    "class NgkKernel:\n",
    "    def __init__(self, k):\n",
    "        self.k = k        \n",
    "        #dictionary with the cached results of kernel evaluation\n",
    "        self.cache_dict = {}\n",
    "        \n",
    "    def create_ngrams(self, text, n):\n",
    "        \"\"\"Create a set of ngrams of length n\"\"\"\n",
    "        return set(text[i:i+n] for i in range(len(text)-n+1))\n",
    "\n",
    "\n",
    "    def ngk_calc(self, doc1, doc2, n):\n",
    "        sd1 = self.create_ngrams(doc1, n)\n",
    "        sd2 = self.create_ngrams(doc2, n)\n",
    "        #print sd1\n",
    "        #print sd2\n",
    "        if len(sd1 | sd2) == 0:\n",
    "            return 1.0\n",
    "\n",
    "        return len(sd1 & sd2) * 1.0 / len(sd1 | sd2)\n",
    "    \n",
    "    def calc_gram_mat(self, X, Y=None):        \n",
    "        sym = False\n",
    "        if Y is None:\n",
    "            sym = True\n",
    "            Y = X\n",
    "        n = len(X)\n",
    "        m = len(Y)\n",
    "        gram_matrix = np.zeros(shape=(n,m))\n",
    "        for i in range(n):\n",
    "            for j in range(m):\n",
    "                if sym and j < i:  # using symetry\n",
    "                    continue               \n",
    "            \n",
    "                if (X[i],Y[j]) in self.cache_dict:\n",
    "                    gram_matrix[i][j] =  self.cache_dict[(X[i],Y[j])]\n",
    "                    if sym: \n",
    "                        gram_matrix[j][i] = self.cache_dict[(X[i],Y[j])]\n",
    "                else:\n",
    "                    res = self.ngk_calc(X[i],Y[j], self.k)\n",
    "                    gram_matrix[i][j] =  res\n",
    "                    if sym:\n",
    "                        gram_matrix[j][i] = res\n",
    "                    self.cache_dict[(X[i],Y[j])] = res\n",
    "                    if sym:\n",
    "                        self.cache_dict[(Y[j],X[i])] = res\n",
    "        return gram_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SSK kernel implementation as proposed by [2] and copied from: https://github.com/muggin/string-kernels/blob/master/src/ssk_kernel.py\n",
    "\n",
    "import math\n",
    "import itertools as iter\n",
    "import numpy as np\n",
    "\n",
    "from string import lowercase\n",
    "\n",
    "class SskKernel:\n",
    "    def __init__(self, k, l):\n",
    "        self.k = k\n",
    "        self.l = l\n",
    "        #dictionary with the cached results of kernel evaluation\n",
    "        self.cache_dict = {}\n",
    "        \n",
    "    def ssk_calc(self, s, t, k, l):        \n",
    "        \"\"\"\n",
    "        Recursive SSK implementation.\n",
    "        :param s: document #1\n",
    "        :param t: document #2\n",
    "        :param k: subsequence length\n",
    "        :param l: weight decay (lambda)\n",
    "        :return: similarity of given documents\n",
    "        return:\n",
    "        \"\"\"\n",
    "        K_prime = self._compute_K_prime(s, t, k, l)\n",
    "        K_st = self._compute_K(s, t, k, l, K_prime)\n",
    "\n",
    "        K_prime = self._compute_K_prime(s, s, k, l)\n",
    "        K_ss = self._compute_K(s, s, k, l, K_prime)\n",
    "\n",
    "        K_prime = self._compute_K_prime(t, t, k, l)\n",
    "        K_tt = self._compute_K(t, t, k, l, K_prime)\n",
    "\n",
    "        denominator = math.sqrt(K_ss * K_tt) if K_ss * K_tt else 10e-20\n",
    "        return K_st / denominator\n",
    "\n",
    "\n",
    "    def _compute_K(self, s, t, k, l, K_prime):\n",
    "        \"\"\"\n",
    "        Compute and return the K in a recursive manner using precomputed K'\n",
    "        \"\"\"\n",
    "        K_val = 0\n",
    "\n",
    "        for m in xrange(len(s)+1):\n",
    "            if min(len(s[:m]), len(t)) < k:\n",
    "                continue\n",
    "\n",
    "            K_val += l**2 * sum([K_prime[k-1][len(s[:m])-1][j] for j in self._find_all_char_indices(s[m-1], t)])\n",
    "\n",
    "        return K_val\n",
    "\n",
    "\n",
    "    def _compute_K_prime(self, s, t, k, l):\n",
    "        \"\"\"\n",
    "        Compute and return K' using the efficient DP algorithm (K'')\n",
    "        \"\"\"\n",
    "        K_prime = np.ones((k, len(s)+1, len(t)+1))\n",
    "        K_dprime = np.zeros((k, len(s)+1, len(t)+1))\n",
    "\n",
    "        for i in xrange(1, k):\n",
    "            for m in xrange(len(s)+1):\n",
    "                for n in xrange(len(t)+1):\n",
    "                    if min(m, n) < i:\n",
    "                        K_prime[i][m][n] = 0\n",
    "                        continue\n",
    "\n",
    "                    if s[m-1] != t[n-1]:\n",
    "                        K_dprime[i][m][n] = l*K_dprime[i][m][n-1]\n",
    "                    else:\n",
    "                        K_dprime[i][m][n] = l*(K_dprime[i][m][n-1] + l*K_prime[i-1][m-1][n-1])\n",
    "\n",
    "                    K_prime[i][m][n] = l*K_prime[i][m-1][n] + K_dprime[i][m][n]\n",
    "\n",
    "        return K_prime\n",
    "\n",
    "    def _find_all_char_indices(self, char, string):\n",
    "        return [idx for idx, ltr in enumerate(string) if ltr == char]\n",
    "\n",
    "    def calc_gram_mat(self, X, Y=None):\n",
    "        sym = False\n",
    "        if Y is None:\n",
    "            sym = True\n",
    "            Y = X\n",
    "        n = len(X)\n",
    "        m = len(Y)\n",
    "        gram_matrix = np.zeros(shape=(n,m))\n",
    "        for i in range(n):\n",
    "            for j in range(m):\n",
    "                if sym and j < i:  # using symetry\n",
    "                    continue               \n",
    "            \n",
    "                if (X[i],Y[j]) in self.cache_dict:\n",
    "                    gram_matrix[i][j] =  self.cache_dict[(X[i],Y[j])]\n",
    "                    if sym: \n",
    "                        gram_matrix[j][i] = self.cache_dict[(X[i],Y[j])]\n",
    "                else:\n",
    "                    res = self.ssk_calc(X[i],Y[j], self.k, self.l)\n",
    "                    gram_matrix[i][j] =  res\n",
    "                    if sym:\n",
    "                        gram_matrix[j][i] = res\n",
    "                    self.cache_dict[(X[i],Y[j])] = res\n",
    "                    if sym:\n",
    "                        self.cache_dict[(Y[j],X[i])] = res\n",
    "        return gram_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For our datasets using small experiments we have discovered that $n=3$ is a good estimation of the best value for $n$ , then we will explore around this value $n = (2,3,4)$ and in order to cover more or less extreme and central values for $\\lambda$ we will explore $\\lambda = (0.01,0.25,0.5,0.75,0.99)$. Furthermore, using the same argument as with $\\lambda$ we will vary hyperparameter C as $C = (2^{-10},2^{-5},2^{0},2^{5},2^{10})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in order to make results easier, we will use the same technique as [1] and\n",
    "#vary only one of the parameters (lambda or n)\n",
    "\n",
    "#kernels for n = 3 constant\n",
    "#SSK kernels with n = 3 constant , lambda = (0.01,0.25,0.5,0.75,0.99)\n",
    "ssk_3_01 = SskKernel(3,0.01)\n",
    "ssk_3_25 = SskKernel(3,0.25)\n",
    "ssk_3_50 = SskKernel(3,0.5)\n",
    "ssk_3_75 = SskKernel(3,0.75)\n",
    "ssk_3_99 = SskKernel(3,0.99)\n",
    "#NGK kernel with n = 3 constant\n",
    "ngk_3 = NgkKernel(3)\n",
    "\n",
    "#kernels for lambda = 0.5 constant\n",
    "#SSK kernels with n = (2,3,4), lambda = 0.5 constant\n",
    "ssk_2_50 = SskKernel(2,0.5)\n",
    "#ssk_3_50 = SskKernel(3,0.5) (already defined and can be reused)\n",
    "ssk_4_50 = SskKernel(4,0.5)\n",
    "#NGK kernel with n = (2,3,4)\n",
    "ngk_2 = NgkKernel(2) \n",
    "#ngk_3 = NgkKernel(3) (already defined and can be reused)\n",
    "ngk_4 = NgkKernel(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training all the kernels for C=2^-10\n",
    "print \"starting time: \" , datetime.datetime.now()\n",
    "\n",
    "clf_0_ssk_3_01 = SVC(kernel='precomputed',C=np.power(2.0,-10))\n",
    "gram_mat = ssk_3_01.calc_gram_mat(train)\n",
    "clf_0_ssk_3_01.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_0_ssk_3_01, gram_mat, target, cv=5)\n",
    "print \"clf 0 ssk 3 01=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_0_ssk_3_25 = SVC(kernel='precomputed',C=np.power(2.0,-10))\n",
    "gram_mat = ssk_3_25.calc_gram_mat(train)\n",
    "clf_0_ssk_3_25.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_0_ssk_3_25, gram_mat, target, cv=5)\n",
    "print \"clf 0 ssk 3 25=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_0_ssk_3_50 = SVC(kernel='precomputed',C=np.power(2.0,-10))\n",
    "gram_mat = ssk_3_50.calc_gram_mat(train)\n",
    "clf_0_ssk_3_50.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_0_ssk_3_50, gram_mat, target, cv=5)\n",
    "print \"clf 0 ssk 3 50=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_0_ssk_3_75 = SVC(kernel='precomputed',C=np.power(2.0,-10))\n",
    "gram_mat = ssk_3_75.calc_gram_mat(train)\n",
    "clf_0_ssk_3_75.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_0_ssk_3_75, gram_mat, target, cv=5)\n",
    "print \"clf 0 ssk 3 75=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_0_ssk_3_99 = SVC(kernel='precomputed',C=np.power(2.0,-10))\n",
    "gram_mat = ssk_3_99.calc_gram_mat(train)\n",
    "clf_0_ssk_3_99.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_0_ssk_3_99, gram_mat, target, cv=5)\n",
    "print \"clf 0 ssk 3 99=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_0_ssk_2_50 = SVC(kernel='precomputed',C=np.power(2.0,-10))\n",
    "gram_mat = ssk_2_50.calc_gram_mat(train)\n",
    "clf_0_ssk_2_50.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_0_ssk_2_50, gram_mat, target, cv=5)\n",
    "print \"clf 0 ssk 2 50=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_0_ssk_4_50 = SVC(kernel='precomputed',C=np.power(2.0,-10))\n",
    "gram_mat = ssk_4_50.calc_gram_mat(train)\n",
    "clf_0_ssk_4_50.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_0_ssk_4_50, gram_mat, target, cv=5)\n",
    "print \"clf 0 ssk 4 50=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_0_ngk_2 = SVC(kernel='precomputed',C=np.power(2.0,-10))\n",
    "gram_mat = ngk_2.calc_gram_mat(train)\n",
    "clf_0_ngk_2.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_0_ngk_2, gram_mat, target, cv=5)\n",
    "print \"clf 0 ngk 2=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_0_ngk_3 = SVC(kernel='precomputed',C=np.power(2.0,-10))\n",
    "gram_mat = ngk_3.calc_gram_mat(train)\n",
    "clf_0_ngk_3.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_0_ngk_3, gram_mat, target, cv=5)\n",
    "print \"clf 0 ngk 3=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_0_ngk_4 = SVC(kernel='precomputed',C=np.power(2.0,-10))\n",
    "gram_mat = ngk_4.calc_gram_mat(train)\n",
    "clf_0_ngk_4.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_0_ngk_4, gram_mat, target, cv=5)\n",
    "print \"clf 0 ngk 4=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "print \"finishing time: \" , datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training all the kernels for C=2^-5\n",
    "clf_1_ssk_3_01 = SVC(kernel='precomputed',C=np.power(2.0,-5))\n",
    "gram_mat = ssk_3_01.calc_gram_mat(train)\n",
    "clf_1_ssk_3_01.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_1_ssk_3_01, gram_mat, target, cv=5)\n",
    "print \"clf 1 ssk 3 01=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_1_ssk_3_25 = SVC(kernel='precomputed',C=np.power(2.0,-5))\n",
    "gram_mat = ssk_3_25.calc_gram_mat(train)\n",
    "clf_1_ssk_3_25.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_1_ssk_3_25, gram_mat, target, cv=5)\n",
    "print \"clf 1 ssk 3 25=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_1_ssk_3_50 = SVC(kernel='precomputed',C=np.power(2.0,-5))\n",
    "gram_mat = ssk_3_50.calc_gram_mat(train)\n",
    "clf_1_ssk_3_50.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_1_ssk_3_50, gram_mat, target, cv=5)\n",
    "print \"clf 1 ssk 3 50=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_1_ssk_3_75 = SVC(kernel='precomputed',C=np.power(2.0,-5))\n",
    "gram_mat = ssk_3_75.calc_gram_mat(train)\n",
    "clf_1_ssk_3_75.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_1_ssk_3_75, gram_mat, target, cv=5)\n",
    "print \"clf 1 ssk 3 75=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_1_ssk_3_99 = SVC(kernel='precomputed',C=np.power(2.0,-5))\n",
    "gram_mat = ssk_3_99.calc_gram_mat(train)\n",
    "clf_1_ssk_3_99.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_1_ssk_3_99, gram_mat, target, cv=5)\n",
    "print \"clf 1 ssk 3 99=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_1_ssk_2_50 = SVC(kernel='precomputed',C=np.power(2.0,-5))\n",
    "gram_mat = ssk_2_50.calc_gram_mat(train)\n",
    "clf_1_ssk_2_50.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_1_ssk_2_50, gram_mat, target, cv=5)\n",
    "print \"clf 1 ssk 2 50=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_1_ssk_4_50 = SVC(kernel='precomputed',C=np.power(2.0,-5))\n",
    "gram_mat = ssk_4_50.calc_gram_mat(train)\n",
    "clf_1_ssk_4_50.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_1_ssk_4_50, gram_mat, target, cv=5)\n",
    "print \"clf 1 ssk 4 50=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_1_ngk_2 = SVC(kernel='precomputed',C=np.power(2.0,-5))\n",
    "gram_mat = ngk_2.calc_gram_mat(train)\n",
    "clf_1_ngk_2.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_1_ngk_2, gram_mat, target, cv=5)\n",
    "print \"clf 1 ngk 2=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_1_ngk_3 = SVC(kernel='precomputed',C=np.power(2.0,-5))\n",
    "gram_mat = ngk_3.calc_gram_mat(train)\n",
    "clf_1_ngk_3.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_1_ngk_3, gram_mat, target, cv=5)\n",
    "print \"clf 1 ngk 3=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_1_ngk_4 = SVC(kernel='precomputed',C=np.power(2.0,-5))\n",
    "gram_mat = ngk_4.calc_gram_mat(train)\n",
    "clf_1_ngk_4.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_1_ngk_4, gram_mat, target, cv=5)\n",
    "print \"clf 1 ngk 4=> mean: \", scores.mean(), \" std: \", scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training all the kernels for C=2^0\n",
    "clf_2_ssk_3_01 = SVC(kernel='precomputed')\n",
    "gram_mat = ssk_3_01.calc_gram_mat(train)\n",
    "clf_2_ssk_3_01.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_2_ssk_3_01, gram_mat, target, cv=5)\n",
    "print \"clf 2 ssk 3 01=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_2_ssk_3_25 = SVC(kernel='precomputed')\n",
    "gram_mat = ssk_3_25.calc_gram_mat(train)\n",
    "clf_2_ssk_3_25.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_2_ssk_3_25, gram_mat, target, cv=5)\n",
    "print \"clf 2 ssk 3 25=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_2_ssk_3_50 = SVC(kernel='precomputed')\n",
    "gram_mat = ssk_3_50.calc_gram_mat(train)\n",
    "clf_2_ssk_3_50.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_2_ssk_3_50, gram_mat, target, cv=5)\n",
    "print \"clf 2 ssk 3 50=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_2_ssk_3_75 = SVC(kernel='precomputed')\n",
    "gram_mat = ssk_3_75.calc_gram_mat(train)\n",
    "clf_2_ssk_3_75.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_2_ssk_3_75, gram_mat, target, cv=5)\n",
    "print \"clf 2 ssk 3 75=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_2_ssk_3_99 = SVC(kernel='precomputed')\n",
    "gram_mat = ssk_3_99.calc_gram_mat(train)\n",
    "clf_2_ssk_3_99.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_2_ssk_3_99, gram_mat, target, cv=5)\n",
    "print \"clf 2 ssk 3 99=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_2_ssk_2_50 = SVC(kernel='precomputed')\n",
    "gram_mat = ssk_2_50.calc_gram_mat(train)\n",
    "clf_2_ssk_2_50.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_2_ssk_2_50, gram_mat, target, cv=5)\n",
    "print \"clf 2 ssk 2 50=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_2_ssk_4_50 = SVC(kernel='precomputed')\n",
    "gram_mat = ssk_4_50.calc_gram_mat(train)\n",
    "clf_2_ssk_4_50.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_2_ssk_4_50, gram_mat, target, cv=5)\n",
    "print \"clf 2 ssk 4 50=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_2_ngk_2 = SVC(kernel='precomputed')\n",
    "gram_mat = ngk_2.calc_gram_mat(train)\n",
    "clf_2_ngk_2.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_2_ngk_2, gram_mat, target, cv=5)\n",
    "print \"clf 2 ngk 2=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_2_ngk_3 = SVC(kernel='precomputed')\n",
    "gram_mat = ngk_3.calc_gram_mat(train)\n",
    "clf_2_ngk_3.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_2_ngk_3, gram_mat, target, cv=5)\n",
    "print \"clf 2 ngk 3=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_2_ngk_4 = SVC(kernel='precomputed')\n",
    "gram_mat = ngk_4.calc_gram_mat(train)\n",
    "clf_2_ngk_4.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_2_ngk_4, gram_mat, target, cv=5)\n",
    "print \"clf 2 ngk 4=> mean: \", scores.mean(), \" std: \", scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training all the kernels for C=2^5\n",
    "clf_3_ssk_3_01 = SVC(kernel='precomputed',C=np.power(2.0,5))\n",
    "gram_mat = ssk_3_01.calc_gram_mat(train)\n",
    "clf_3_ssk_3_01.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_3_ssk_3_01, gram_mat, target, cv=5)\n",
    "print \"clf 3 ssk 3 01=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_3_ssk_3_25 = SVC(kernel='precomputed',C=np.power(2.0,5))\n",
    "gram_mat = ssk_3_25.calc_gram_mat(train)\n",
    "clf_3_ssk_3_25.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_3_ssk_3_25, gram_mat, target, cv=5)\n",
    "print \"clf 3 ssk 3 25=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_3_ssk_3_50 = SVC(kernel='precomputed',C=np.power(2.0,5))\n",
    "gram_mat = ssk_3_50.calc_gram_mat(train)\n",
    "clf_3_ssk_3_50.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_3_ssk_3_50, gram_mat, target, cv=5)\n",
    "print \"clf 3 ssk 3 50=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_3_ssk_3_75 = SVC(kernel='precomputed',C=np.power(2.0,5))\n",
    "gram_mat = ssk_3_75.calc_gram_mat(train)\n",
    "clf_3_ssk_3_75.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_3_ssk_3_75, gram_mat, target, cv=5)\n",
    "print \"clf 3 ssk 3 75=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_3_ssk_3_99 = SVC(kernel='precomputed',C=np.power(2.0,5))\n",
    "gram_mat = ssk_3_99.calc_gram_mat(train)\n",
    "clf_3_ssk_3_99.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_3_ssk_3_99, gram_mat, target, cv=5)\n",
    "print \"clf 3 ssk 3 99=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_3_ssk_2_50 = SVC(kernel='precomputed',C=np.power(2.0,5))\n",
    "gram_mat = ssk_2_50.calc_gram_mat(train)\n",
    "clf_3_ssk_2_50.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_3_ssk_2_50, gram_mat, target, cv=5)\n",
    "print \"clf 3 ssk 2 50=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_3_ssk_4_50 = SVC(kernel='precomputed',C=np.power(2.0,5))\n",
    "gram_mat = ssk_4_50.calc_gram_mat(train)\n",
    "clf_3_ssk_4_50.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_3_ssk_4_50, gram_mat, target, cv=5)\n",
    "print \"clf 3 ssk 4 50=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_3_ngk_2 = SVC(kernel='precomputed',C=np.power(2.0,5))\n",
    "gram_mat = ngk_2.calc_gram_mat(train)\n",
    "clf_3_ngk_2.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_3_ngk_2, gram_mat, target, cv=5)\n",
    "print \"clf 3 ngk 2=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_3_ngk_3 = SVC(kernel='precomputed',C=np.power(2.0,5))\n",
    "gram_mat = ngk_3.calc_gram_mat(train)\n",
    "clf_3_ngk_3.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_3_ngk_3, gram_mat, target, cv=5)\n",
    "print \"clf 3 ngk 3=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_3_ngk_4 = SVC(kernel='precomputed',C=np.power(2.0,5))\n",
    "gram_mat = ngk_4.calc_gram_mat(train)\n",
    "clf_3_ngk_4.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_3_ngk_4, gram_mat, target, cv=5)\n",
    "print \"clf 3 ngk 4=> mean: \", scores.mean(), \" std: \", scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training all the kernels for C=2^10\n",
    "print \"starting time: \" , datetime.datetime.now()\n",
    "\n",
    "clf_4_ssk_3_01 = SVC(kernel='precomputed',C=np.power(2.0,10))\n",
    "gram_mat = ssk_3_01.calc_gram_mat(train)\n",
    "clf_4_ssk_3_01.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_4_ssk_3_01, gram_mat, target, cv=5)\n",
    "print \"clf 3 ssk 3 01=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_4_ssk_3_25 = SVC(kernel='precomputed',C=np.power(2.0,10))\n",
    "gram_mat = ssk_3_25.calc_gram_mat(train)\n",
    "clf_4_ssk_3_25.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_4_ssk_3_25, gram_mat, target, cv=5)\n",
    "print \"clf 3 ssk 3 25=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_4_ssk_3_50 = SVC(kernel='precomputed',C=np.power(2.0,10))\n",
    "gram_mat = ssk_3_50.calc_gram_mat(train)\n",
    "clf_4_ssk_3_50.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_4_ssk_3_50, gram_mat, target, cv=5)\n",
    "print \"clf 3 ssk 3 50=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_4_ssk_3_75 = SVC(kernel='precomputed',C=np.power(2.0,10))\n",
    "gram_mat = ssk_3_75.calc_gram_mat(train)\n",
    "clf_4_ssk_3_75.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_4_ssk_3_75, gram_mat, target, cv=5)\n",
    "print \"clf 3 ssk 3 75=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_4_ssk_3_99 = SVC(kernel='precomputed',C=np.power(2.0,10))\n",
    "gram_mat = ssk_3_99.calc_gram_mat(train)\n",
    "clf_4_ssk_3_99.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_4_ssk_3_99, gram_mat, target, cv=5)\n",
    "print \"clf 3 ssk 3 99=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_4_ssk_2_50 = SVC(kernel='precomputed',C=np.power(2.0,10))\n",
    "gram_mat = ssk_2_50.calc_gram_mat(train)\n",
    "clf_4_ssk_2_50.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_4_ssk_2_50, gram_mat, target, cv=5)\n",
    "print \"clf 3 ssk 2 50=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_4_ssk_4_50 = SVC(kernel='precomputed',C=np.power(2.0,10))\n",
    "gram_mat = ssk_4_50.calc_gram_mat(train)\n",
    "clf_4_ssk_4_50.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_4_ssk_4_50, gram_mat, target, cv=5)\n",
    "print \"clf 3 ssk 4 50=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_4_ngk_2 = SVC(kernel='precomputed',C=np.power(2.0,10))\n",
    "gram_mat = ngk_2.calc_gram_mat(train)\n",
    "clf_4_ngk_2.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_4_ngk_2, gram_mat, target, cv=5)\n",
    "print \"clf 3 ngk 2=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_4_ngk_3 = SVC(kernel='precomputed',C=np.power(2.0,10))\n",
    "gram_mat = ngk_3.calc_gram_mat(train)\n",
    "clf_4_ngk_3.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_4_ngk_3, gram_mat, target, cv=5)\n",
    "print \"clf 3 ngk 3=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_4_ngk_4 = SVC(kernel='precomputed',C=np.power(2.0,10))\n",
    "gram_mat = ngk_4.calc_gram_mat(train)\n",
    "clf_4_ngk_4.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_4_ngk_4, gram_mat, target, cv=5)\n",
    "print \"clf 3 ngk 4=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "print \"finishing time: \" , datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d)\n",
    "\n",
    "##### i. The Summarize of the results are presented in the following table ( In red the best results for SSK and in blue the best results for NGK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;border-color:#ccc;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#ccc;color:#333;background-color:#fff;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#ccc;color:#333;background-color:#f0f0f0;}\n",
    ".tg .tg-u2wy{background-color:#f9f9f9;font-weight:bold;border-color:inherit;vertical-align:top}\n",
    ".tg .tg-zx9n{background-color:#f9f9f9;font-weight:bold;font-family:Arial, Helvetica, sans-serif !important;;border-color:inherit;vertical-align:top}\n",
    ".tg .tg-dc35{background-color:#f9f9f9;border-color:inherit;vertical-align:top}\n",
    ".tg .tg-us36{border-color:inherit;vertical-align:top}\n",
    ".tg .tg-c0ir{background-color:#32cb00;border-color:inherit;vertical-align:top}\n",
    ".tg .tg-p8bj{font-weight:bold;border-color:inherit;vertical-align:top}\n",
    ".tg .tg-7btt{font-weight:bold;border-color:inherit;text-align:center;vertical-align:top}\n",
    ".tg .tg-80xr{background-color:#00009b;border-color:inherit;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-p8bj\" rowspan=\"2\">Kernel<br></th>\n",
    "    <th class=\"tg-7btt\" rowspan=\"2\">C</th>\n",
    "    <th class=\"tg-7btt\" rowspan=\"2\">&lambda;<br></th>\n",
    "    <th class=\"tg-p8bj\" rowspan=\"2\">n</th>\n",
    "    <th class=\"tg-p8bj\" colspan=\"2\">5-fold cross validation<br></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-u2wy\">Mean<br></td>\n",
    "    <td class=\"tg-u2wy\">Std<br></td>\n",
    "  </tr>\n",
    "  <tr bgcolor=\"#FF0000\" fontcolor=\"#FF0000\">\n",
    "    <td class=\"tg-p8bj\" rowspan=\"7\">SSK</td>\n",
    "    <td class=\"tg-us36\">$2^{-10}$</td>\n",
    "    <td class=\"tg-us36\">0.01</td>\n",
    "    <td class=\"tg-us36\">3<br></td>\n",
    "    <td class=\"tg-us36\">0.751</td>\n",
    "    <td class=\"tg-us36\">0.057</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-dc35\">$2^{-10}$</td>\n",
    "    <td class=\"tg-dc35\">0.25</td>\n",
    "    <td class=\"tg-dc35\">3</td>\n",
    "    <td class=\"tg-dc35\">0.780</td>\n",
    "    <td class=\"tg-dc35\">0.042</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-us36\">$2^{-10}$</td>\n",
    "    <td class=\"tg-us36\">0.5</td>\n",
    "    <td class=\"tg-us36\">3</td>\n",
    "    <td class=\"tg-us36\">0.782</td>\n",
    "    <td class=\"tg-us36\">0.031</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-dc35\">$2^{-10}$</td>\n",
    "    <td class=\"tg-dc35\">0.75</td>\n",
    "    <td class=\"tg-dc35\">3</td>\n",
    "    <td class=\"tg-dc35\">0.729</td>\n",
    "    <td class=\"tg-dc35\">0.038</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-us36\">$2^{-10}$</td>\n",
    "    <td class=\"tg-us36\">0.99</td>\n",
    "    <td class=\"tg-us36\">3</td>\n",
    "    <td class=\"tg-us36\">0.672</td>\n",
    "    <td class=\"tg-us36\">0.031</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-dc35\">$2^{-10}$</td>\n",
    "    <td class=\"tg-dc35\">0.5</td>\n",
    "    <td class=\"tg-dc35\">2</td>\n",
    "    <td class=\"tg-dc35\">0.769</td>\n",
    "    <td class=\"tg-dc35\">0.028</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-c0ir\">$2^{-10}$</td>\n",
    "    <td class=\"tg-c0ir\">0.5</td>\n",
    "    <td class=\"tg-c0ir\">4<br></td>\n",
    "    <td class=\"tg-c0ir\">0.659</td>\n",
    "    <td class=\"tg-c0ir\">0.080</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-zx9n\" rowspan=\"3\">NGK</td>\n",
    "    <td class=\"tg-dc35\">$2^{-10}$</td>\n",
    "    <td class=\"tg-dc35\">NA<br></td>\n",
    "    <td class=\"tg-dc35\">2</td>\n",
    "    <td class=\"tg-dc35\">0.771</td>\n",
    "    <td class=\"tg-dc35\">0.027</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-us36\">$2^{-10}$</td>\n",
    "    <td class=\"tg-us36\">NA</td>\n",
    "    <td class=\"tg-us36\">3</td>\n",
    "    <td class=\"tg-us36\">0.758</td>\n",
    "    <td class=\"tg-us36\">0.073</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-80xr\">$2^{-10}$</td>\n",
    "    <td class=\"tg-80xr\">NA</td>\n",
    "    <td class=\"tg-80xr\">4</td>\n",
    "    <td class=\"tg-80xr\">0.674</td>\n",
    "    <td class=\"tg-80xr\">0.099</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td class=\"tg-p8bj\" rowspan=\"7\">SSK</td>\n",
    "    <td class=\"tg-us36\">$2^{-5}$</td>\n",
    "    <td class=\"tg-us36\">0.01</td>\n",
    "    <td class=\"tg-us36\">3<br></td>\n",
    "    <td class=\"tg-us36\">0.751</td>\n",
    "    <td class=\"tg-us36\">0.057</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-dc35\">$2^{-5}$</td>\n",
    "    <td class=\"tg-dc35\">0.25</td>\n",
    "    <td class=\"tg-dc35\">3</td>\n",
    "    <td class=\"tg-dc35\">0.780</td>\n",
    "    <td class=\"tg-dc35\">0.042</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-us36\">$2^{-5}$</td>\n",
    "    <td class=\"tg-us36\">0.5</td>\n",
    "    <td class=\"tg-us36\">3</td>\n",
    "    <td class=\"tg-us36\">0.782</td>\n",
    "    <td class=\"tg-us36\">0.031</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-dc35\">$2^{-5}$</td>\n",
    "    <td class=\"tg-dc35\">0.75</td>\n",
    "    <td class=\"tg-dc35\">3</td>\n",
    "    <td class=\"tg-dc35\">0.729</td>\n",
    "    <td class=\"tg-dc35\">0.038</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-us36\">$2^{-5}$</td>\n",
    "    <td class=\"tg-us36\">0.99</td>\n",
    "    <td class=\"tg-us36\">3</td>\n",
    "    <td class=\"tg-us36\">0.672</td>\n",
    "    <td class=\"tg-us36\">0.031</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-dc35\">$2^{-5}$</td>\n",
    "    <td class=\"tg-dc35\">0.5</td>\n",
    "    <td class=\"tg-dc35\">2</td>\n",
    "    <td class=\"tg-dc35\">0.769</td>\n",
    "    <td class=\"tg-dc35\">0.028</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-c0ir\">$2^{-5}$</td>\n",
    "    <td class=\"tg-c0ir\">0.5</td>\n",
    "    <td class=\"tg-c0ir\">4<br></td>\n",
    "    <td class=\"tg-c0ir\">0.659</td>\n",
    "    <td class=\"tg-c0ir\">0.080</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-zx9n\" rowspan=\"3\">NGK</td>\n",
    "    <td class=\"tg-dc35\">$2^{-5}$</td>\n",
    "    <td class=\"tg-dc35\">NA<br></td>\n",
    "    <td class=\"tg-dc35\">2</td>\n",
    "    <td class=\"tg-dc35\">0.771</td>\n",
    "    <td class=\"tg-dc35\">0.027</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-us36\">$2^{-5}$</td>\n",
    "    <td class=\"tg-us36\">NA</td>\n",
    "    <td class=\"tg-us36\">3</td>\n",
    "    <td class=\"tg-us36\">0.758</td>\n",
    "    <td class=\"tg-us36\">0.073</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-80xr\">$2^{-5}$</td>\n",
    "    <td class=\"tg-80xr\">NA</td>\n",
    "    <td class=\"tg-80xr\">4</td>\n",
    "    <td class=\"tg-80xr\">0.674</td>\n",
    "    <td class=\"tg-80xr\">0.099</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td class=\"tg-p8bj\" rowspan=\"7\">SSK</td>\n",
    "    <td class=\"tg-us36\">$2^{0}$</td>\n",
    "    <td class=\"tg-us36\">0.01</td>\n",
    "    <td class=\"tg-us36\">3<br></td>\n",
    "    <td class=\"tg-us36\">0.839</td>\n",
    "    <td class=\"tg-us36\">0.016</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-dc35\">$2^{0}$</td>\n",
    "    <td class=\"tg-dc35\">0.25</td>\n",
    "    <td class=\"tg-dc35\">3</td>\n",
    "    <td class=\"tg-dc35\">0.855</td>\n",
    "    <td class=\"tg-dc35\">0.017</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-us36\">$2^{0}$</td>\n",
    "    <td class=\"tg-us36\">0.5</td>\n",
    "    <td class=\"tg-us36\">3</td>\n",
    "    <td class=\"tg-us36\">0.860</td>\n",
    "    <td class=\"tg-us36\">0.025</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td bgcolor=\"#ff1a1a\">$2^{0}$</td>\n",
    "    <td bgcolor=\"#ff1a1a\">0.75</td>\n",
    "    <td bgcolor=\"#ff1a1a\">3</td>\n",
    "    <td bgcolor=\"#ff1a1a\">0.860</td>\n",
    "    <td bgcolor=\"#ff1a1a\">0.023</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-us36\">$2^{0}$</td>\n",
    "    <td class=\"tg-us36\">0.99</td>\n",
    "    <td class=\"tg-us36\">3</td>\n",
    "    <td class=\"tg-us36\">0.853</td>\n",
    "    <td class=\"tg-us36\">0.023</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-dc35\">$2^{0}$</td>\n",
    "    <td class=\"tg-dc35\">0.5</td>\n",
    "    <td class=\"tg-dc35\">2</td>\n",
    "    <td class=\"tg-dc35\">0.853</td>\n",
    "    <td class=\"tg-dc35\">0.025</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-c0ir\">$2^{0}$</td>\n",
    "    <td class=\"tg-c0ir\">0.5</td>\n",
    "    <td class=\"tg-c0ir\">4<br></td>\n",
    "    <td class=\"tg-c0ir\">0.807</td>\n",
    "    <td class=\"tg-c0ir\">0.033</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-zx9n\" rowspan=\"3\">NGK</td>\n",
    "    <td bgcolor=\"#3366ff\">$2^{0}$</td>\n",
    "    <td bgcolor=\"#3366ff\">NA<br></td>\n",
    "    <td bgcolor=\"#3366ff\">2</td>\n",
    "    <td bgcolor=\"#3366ff\">0.871</td>\n",
    "    <td bgcolor=\"#3366ff\">0.024</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-us36\">$2^{0}$</td>\n",
    "    <td class=\"tg-us36\">NA</td>\n",
    "    <td class=\"tg-us36\">3</td>\n",
    "    <td class=\"tg-us36\">0.845</td>\n",
    "    <td class=\"tg-us36\">0.022</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-80xr\">$2^{0}$</td>\n",
    "    <td class=\"tg-80xr\">NA</td>\n",
    "    <td class=\"tg-80xr\">4</td>\n",
    "    <td class=\"tg-80xr\">0.785</td>\n",
    "    <td class=\"tg-80xr\">0.027</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td class=\"tg-p8bj\" rowspan=\"7\">SSK</td>\n",
    "    <td class=\"tg-us36\">$2^{5}$</td>\n",
    "    <td class=\"tg-us36\">0.01</td>\n",
    "    <td class=\"tg-us36\">3<br></td>\n",
    "    <td class=\"tg-us36\">0.819</td>\n",
    "    <td class=\"tg-us36\">0.018</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-dc35\">$2^{5}$</td>\n",
    "    <td class=\"tg-dc35\">0.25</td>\n",
    "    <td class=\"tg-dc35\">3</td>\n",
    "    <td class=\"tg-dc35\">0.834</td>\n",
    "    <td class=\"tg-dc35\">0.016</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-us36\">$2^{5}$</td>\n",
    "    <td class=\"tg-us36\">0.5</td>\n",
    "    <td class=\"tg-us36\">3</td>\n",
    "    <td class=\"tg-us36\">0.842</td>\n",
    "    <td class=\"tg-us36\">0.023</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-dc35\">$2^{5}$</td>\n",
    "    <td class=\"tg-dc35\">0.75</td>\n",
    "    <td class=\"tg-dc35\">3</td>\n",
    "    <td class=\"tg-dc35\">0.835</td>\n",
    "    <td class=\"tg-dc35\">0.024</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-us36\">$2^{5}$</td>\n",
    "    <td class=\"tg-us36\">0.99</td>\n",
    "    <td class=\"tg-us36\">3</td>\n",
    "    <td class=\"tg-us36\">0.834</td>\n",
    "    <td class=\"tg-us36\">0.022</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-dc35\">$2^{5}$</td>\n",
    "    <td class=\"tg-dc35\">0.5</td>\n",
    "    <td class=\"tg-dc35\">2</td>\n",
    "    <td class=\"tg-dc35\">0.843</td>\n",
    "    <td class=\"tg-dc35\">0.031</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-c0ir\">$2^{5}$</td>\n",
    "    <td class=\"tg-c0ir\">0.5</td>\n",
    "    <td class=\"tg-c0ir\">4<br></td>\n",
    "    <td class=\"tg-c0ir\">0.814</td>\n",
    "    <td class=\"tg-c0ir\">0.031</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-zx9n\" rowspan=\"3\">NGK</td>\n",
    "    <td class=\"tg-dc35\">$2^{5}$</td>\n",
    "    <td class=\"tg-dc35\">NA<br></td>\n",
    "    <td class=\"tg-dc35\">2</td>\n",
    "    <td class=\"tg-dc35\">0.875</td>\n",
    "    <td class=\"tg-dc35\">0.021</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-us36\">$2^{5}$</td>\n",
    "    <td class=\"tg-us36\">NA</td>\n",
    "    <td class=\"tg-us36\">3</td>\n",
    "    <td class=\"tg-us36\">0.845</td>\n",
    "    <td class=\"tg-us36\">0.020</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-80xr\">$2^{5}$</td>\n",
    "    <td class=\"tg-80xr\">NA</td>\n",
    "    <td class=\"tg-80xr\">4</td>\n",
    "    <td class=\"tg-80xr\">0.787</td>\n",
    "    <td class=\"tg-80xr\">0.030</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td class=\"tg-p8bj\" rowspan=\"7\">SSK</td>\n",
    "    <td class=\"tg-us36\">$2^{10}$</td>\n",
    "    <td class=\"tg-us36\">0.01</td>\n",
    "    <td class=\"tg-us36\">3<br></td>\n",
    "    <td class=\"tg-us36\">0.815</td>\n",
    "    <td class=\"tg-us36\">0.021</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-dc35\">$2^{10}$</td>\n",
    "    <td class=\"tg-dc35\">0.25</td>\n",
    "    <td class=\"tg-dc35\">3</td>\n",
    "    <td class=\"tg-dc35\">0.833</td>\n",
    "    <td class=\"tg-dc35\">0.013</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-us36\">$2^{10}$</td>\n",
    "    <td class=\"tg-us36\">0.5</td>\n",
    "    <td class=\"tg-us36\">3</td>\n",
    "    <td class=\"tg-us36\">0.843</td>\n",
    "    <td class=\"tg-us36\">0.024</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-dc35\">$2^{10}$</td>\n",
    "    <td class=\"tg-dc35\">0.75</td>\n",
    "    <td class=\"tg-dc35\">3</td>\n",
    "    <td class=\"tg-dc35\">0.835</td>\n",
    "    <td class=\"tg-dc35\">0.024</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-us36\">$2^{10}$</td>\n",
    "    <td class=\"tg-us36\">0.99</td>\n",
    "    <td class=\"tg-us36\">3</td>\n",
    "    <td class=\"tg-us36\">0.834</td>\n",
    "    <td class=\"tg-us36\">0.022</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-dc35\">$2^{10}$</td>\n",
    "    <td class=\"tg-dc35\">0.5</td>\n",
    "    <td class=\"tg-dc35\">2</td>\n",
    "    <td class=\"tg-dc35\">0.811</td>\n",
    "    <td class=\"tg-dc35\">0.010</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-c0ir\">$2^{10}$</td>\n",
    "    <td class=\"tg-c0ir\">0.5</td>\n",
    "    <td class=\"tg-c0ir\">4<br></td>\n",
    "    <td class=\"tg-c0ir\">0.814</td>\n",
    "    <td class=\"tg-c0ir\">0.031</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-zx9n\" rowspan=\"3\">NGK</td>\n",
    "    <td class=\"tg-dc35\">$2^{10}$</td>\n",
    "    <td class=\"tg-dc35\">NA<br></td>\n",
    "    <td class=\"tg-dc35\">2</td>\n",
    "    <td class=\"tg-dc35\">0.875</td>\n",
    "    <td class=\"tg-dc35\">0.021</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-us36\">$2^{10}$</td>\n",
    "    <td class=\"tg-us36\">NA</td>\n",
    "    <td class=\"tg-us36\">3</td>\n",
    "    <td class=\"tg-us36\">0.845</td>\n",
    "    <td class=\"tg-us36\">0.020</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-80xr\">$2^{10}$</td>\n",
    "    <td class=\"tg-80xr\">NA</td>\n",
    "    <td class=\"tg-80xr\">4</td>\n",
    "    <td class=\"tg-80xr\">0.787</td>\n",
    "    <td class=\"tg-80xr\">0.030</td>\n",
    "  </tr>\n",
    "  \n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Now we will evaluate the performance of the best parameters for both kernels\n",
    "bestSsk = ssk_3_75\n",
    "bestSskModel = clf_2_ssk_3_75\n",
    "bestNgk = ngk_2 = NgkKernel(2) \n",
    "bestNgKModel = clf_2_ngk_2\n",
    "\n",
    "ssk_gram = bestSsk.calc_gram_mat(prod, train)\n",
    "ngk_gram = bestNgk.calc_gram_mat(prod, train)\n",
    "\n",
    "pred_ssk = bestSskModel.predict(ssk_gram)\n",
    "pred_ngk = bestNgKModel.predict(ngk_gram)\n",
    "\n",
    "#we will create the confusion matrix from these results\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "cnf_matrix_ssk = confusion_matrix(true, pred_ssk)\n",
    "cnf_matrix_ngk = confusion_matrix(true, pred_ngk)\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix_ssk, classes=(\"English\",\"Spanish\"),\n",
    "                      title='Using SSK')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix_ngk, classes=(\"English\",\"Spanish\"),\n",
    "                      title='Using NGK')\n",
    "\n",
    "plt.show()\n",
    "# Compute confusion matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_eng = []\n",
    "bad_esp = []\n",
    "\n",
    "for i in range(len(prod)):\n",
    "    if true[i] != pred_ssk[i]:\n",
    "        if true[i] == 0:\n",
    "            bad_eng.append(prod[i])\n",
    "        else:\n",
    "            bad_esp.append(prod[i])\n",
    "            \n",
    "print \"english words classified as spanish: \" , bad_eng[:20]\n",
    "print \"spanish words classified as english: \" , bad_esp[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple possible explanations for the missclasifications:\n",
    "    \n",
    "* There are shared words between english and spanish e.g. extra, come, miles, final, horrible, base, etc.\n",
    "* There are proper names in the datasets e.g. Henry, Jimmy, Johnny, etc.\n",
    "* There are some substrings of the words that belong to the other lanaguage e.g. **is**la, **not**a, **crea**te, etc.\n",
    "\n",
    "#### (iii)\n",
    "\n",
    "* Finding the gram matrix for SSK is very compute intensive and since we obtained comparable results using NGK it is probably not a good kernel for language classification.\n",
    "* Classification for english and spanish is not an easy task since there are some undecidable cases and even words from one language commonly used in the other.\n",
    "* There would be better results if we previously avoid the undecidable cases e.g. club, come, miles, etc. And the proper names e.g. Henry, Jimmy, etc.\n",
    "* It would be easier to classify a text than words since it would provide context to the undecidable cases.\n",
    "* We obtained the best results for SSK with $\\lambda = 0.75, n = 3$ and $C = 1$. Further grid exploration of $\\lambda$ and $C$ around these values would be worthy.\n",
    "* For a bag of words with average length equals to 5 we obtained the best results for $n = 3$ for SSK and $n=2$ for NGK it means that when using substrings kernels like the ones used here, it is not a good idea to start with the average as an estimator of the optimal value of n.\n",
    "* Since we used datasets sorted by the frequency and we used the first $sample\\_size$ values, the most frequent words were used for training, it would be worthy to explore randomness in the seleciton of the training words in order to compare with our approach.\n",
    "\n",
    "\n",
    "### References\n",
    "\n",
    "##### [1] V. Polianskii, B. Godefroy, W. Kryscinski, F. Franzen (2017). Re-implementation and analysis of the \"Text Classification using String Kernels\" paper, by Lodhi, Saunders, Shawe-Taylor, Cristianini and Watkins. Report of Project\n",
    "##### [2]  Lodhi, H., Saunders, C., Shawe-Taylor, J., Cristianini, N., & Watkins, C. (2002). Text classification using string kernels. Journal of Machine Learning Research, 2(Feb), 419-444"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
