{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Assignment 3</h1>\n",
    "<h3>Juan Camilo Castro Pinto</h3>\n",
    "<h3>Andres Felipe Cantor</h3>\n",
    "<br/>\n",
    "\n",
    "### 1.\n",
    "#### (a)\n",
    "\n",
    "let $ x = \\{x_{1}, . . . , x_{n} \\} $ be a subset of a input data set X. Consider a kernel function $$\\it{k} : X \\times X   \\rightarrow \\Re $$ $$ X \\rightarrow \\phi(X)$$\n",
    "\n",
    "Then the average distance to the enter of mass of the image of set x in the feature space is: $$\\frac{1}{n}\\sum_{i=1}^{n}\\lVert\\phi(x_{i})-\\phi_{S}(x)\\rVert$$\n",
    "\n",
    "With $$\\phi_{S}(x) = \\frac{1}{n}\\sum_{i=1}^{n}\\phi(x_{i})$$\n",
    "\n",
    "So taking the definition of $\\lVert x\\rVert$ as $\\sqrt{\\langle x,x \\rangle}$ (not squared). Then we can rewrite $\\lVert\\phi(x_{i})-\\phi_{S}(x)\\rVert$ as \n",
    "\n",
    "$$\\sqrt{\\langle \\phi(x_{i})-\\phi_{S}(x),\\phi(x_{i})-\\phi_{S}(x) \\rangle}$$ By distributive property of dot product\n",
    "\n",
    "$$\\sqrt{\\langle \\phi(x_{i}),\\phi(x_{i}) \\rangle - \\langle \\phi(x_{i}),\\phi_S(x) \\rangle - \\langle \\phi_{S}(x),\\phi(x_{i})\\rangle + \\langle \\phi(x),\\phi_S(x) \\rangle} $$ \n",
    "\n",
    "By commutative property\n",
    "\n",
    "$$\\sqrt{\\langle \\phi(x_{i}),\\phi(x_{i}) \\rangle - 2\\langle \\phi(x_{i}),\\phi_S(x) \\rangle + \\langle \\phi_S(x),\\phi_S(x) \\rangle} $$ \n",
    "\n",
    "Replacing the definition of $\\phi_S(x)$ we have\n",
    "\n",
    "$$\\sqrt{\\langle \\phi(x_{i}),\\phi(x_{i}) \\rangle - 2\\langle \\phi(x_{i}),\\frac{1}{n}\\sum_{j=1}^{n}\\phi(x_{j}) \\rangle + \\langle \\frac{1}{n}\\sum_{j=1}^{n}\\phi(x_{j}),\\frac{1}{n}\\sum_{j=1}^{n}\\phi(x_{j}) \\rangle}$$ \n",
    "\n",
    "Taking out the scalars, we have\n",
    "\n",
    "$$\\sqrt{\\langle \\phi(x_{i}),\\phi(x_{i}) \\rangle - \\frac{2}{n}\\langle \\phi(x_{i}),\\sum_{j=1}^{n}\\phi(x_{j}) \\rangle + \\frac{1}{n^2}\\langle \\sum_{j=1}^{n}\\phi(x_{j}),\\sum_{k=1}^{n}\\phi(x_{k}) \\rangle}$$ \n",
    "\n",
    "By the distributive property of dot product\n",
    "\n",
    "$$\\sqrt{\\langle \\phi(x_{i}),\\phi(x_{i}) \\rangle - \\frac{2}{n} \\sum_{j=1}^{n} \\langle \\phi(x_{i}), \\phi(x_{j}) \\rangle + \\frac{1}{n^2} \\sum_{j=1}^n\\sum_{k=1}^n \\langle \\phi(x_{j}),\\phi(x_{k}) \\rangle}$$\n",
    "\n",
    "Taking into account that $K(x_{i},x_{j}) = \\langle x_{i},x_{j} \\rangle$ we can rewrite the result as:\n",
    "\n",
    "$$\\sqrt{K(x_{i},x_{i}) - \\frac{2}{n} \\sum_{j=1}^{n} K(x_{i},x_{j}) + \\frac{1}{n^2} \\sum_{j=1}^n\\sum_{k=1}^n K(x_{j},x_{k})}$$\n",
    "\n",
    "Finally, we can express the average distance to the center of mass as:\n",
    "\n",
    "$$\\frac{1}{n}\\sum_{i=1}^{n}\\sqrt{K(x_{i},x_{i}) - \\frac{2}{n} \\sum_{j=1}^{n} K(x_{i},x_{j}) + \\frac{1}{n^2} \\sum_{j=1}^n\\sum_{k=1}^n K(x_{j},x_{k})}$$\n",
    "\n",
    "#### (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i.    2.5991877273570343 \n",
      "\n",
      "ii.   7.93374823939363 \n",
      "\n",
      "iii.  699.767261626394 \n",
      "\n",
      "iv.   0.889949553379831 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([[0,1],[-1,3],[2,4],[3,-1],[-1,-2]])\n",
    "\n",
    "def kernel(x , y, ind):\n",
    "    if ind == 0:\n",
    "        return np.dot(x,y)\n",
    "    elif ind == 1:\n",
    "        return np.power(np.dot(x,y),2)\n",
    "    elif ind == 2:\n",
    "        return np.power(np.dot(x,y) + 1,5)\n",
    "    elif ind == 3:\n",
    "        return np.exp(-np.dot(x-y,x-y)/ 2.0)\n",
    "    \n",
    "def average_to_center_mass(x, ind):   \n",
    "    n = x.shape[0]\n",
    "    gram_matrix = np.zeros(shape=(n,n))    \n",
    "    gram_sum = 0.0\n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            gram_matrix[i][j] = gram_matrix[j][i] = kernel(x[i],x[j], ind)\n",
    "            if i == j:\n",
    "                gram_sum += gram_matrix[i][j]\n",
    "            else:\n",
    "                gram_sum += 2*gram_matrix[i][j]\n",
    "    \n",
    "    #print gram_matrix\n",
    "    #print gram_sum\n",
    "    result = 0.0\n",
    "    for i in range(n):\n",
    "        aux = gram_matrix[i][i]\n",
    "        aux2 = 0\n",
    "        for j in range(n):\n",
    "            aux2 += gram_matrix[i][j]\n",
    "        aux -= (2.0/n) * aux2\n",
    "        aux += (1.0/np.power(n,2))*gram_sum        \n",
    "        result += np.sqrt(aux)\n",
    "        \n",
    "    return (1.0/n)*result\n",
    "        \n",
    "print \"i.   \", average_to_center_mass(x,0) , \"\\n\"\n",
    "print \"ii.  \", average_to_center_mass(x,1) , \"\\n\"\n",
    "print \"iii. \", average_to_center_mass(x,2) , \"\\n\"\n",
    "print \"iv.  \", average_to_center_mass(x,3) , \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3\n",
    "#### (a)\n",
    "\n",
    "English Samples were taken from: https://en.wiktionary.org/wiki/Wiktionary:Frequency_lists/Contemporary_fiction <br>\n",
    "Spanish Samples were taken from: https://s3.amazonaws.com/101languages/common-words/spanish.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1775\n",
      "1838\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import datetime\n",
    "\n",
    "file = open(\"english_dataset.txt\", \"r\") \n",
    "eng = filter(bool, file.read().split(\" \"))\n",
    "print len(eng)\n",
    "\n",
    "file = open(\"spanish_dataset.txt\", \"r\") \n",
    "esp = filter(bool, file.read().split(\" \"))\n",
    "print len(esp)\n",
    "\n",
    "#first we need to build the train data and the target classes\n",
    "#target classes: 0 = english , 1 = spanish\n",
    "#train data: we will select the first 'sample_size' samples of the gathered datasets and combine them\n",
    "sample_size = 1000\n",
    "prod_size = 500\n",
    "\n",
    "eng_train = eng[:sample_size]\n",
    "esp_train = esp[:sample_size]\n",
    "train = eng_train + esp_train\n",
    "\n",
    "eng_target = np.zeros(sample_size)\n",
    "esp_target = np.ones(sample_size)\n",
    "target = np.append(eng_target,esp_target)\n",
    "\n",
    "#then we create the production test dataset from the remaining data\n",
    "prod_eng = eng[sample_size+1:sample_size+prod_size+1]\n",
    "prod_esp = esp[sample_size+1:sample_size+prod_size+1]\n",
    "prod = prod_eng + prod_esp\n",
    "\n",
    "true_eng = np.zeros(prod_size)\n",
    "true_esp = np.ones(prod_size)\n",
    "true = np.append(true_eng, true_esp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b)\n",
    "\n",
    "We used the implementation of $n-grams$ and $SSK$ from [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n-grams kernel(NGK) implementation copied from: https://github.com/muggin/string-kernels/blob/master/src/ngk_kernel.py\n",
    "\n",
    "class NgkKernel:\n",
    "    def __init__(self, k):\n",
    "        self.k = k        \n",
    "        #dictionary with the cached results of kernel evaluation\n",
    "        self.cache_dict = {}\n",
    "        \n",
    "    def create_ngrams(self, text, n):\n",
    "        \"\"\"Create a set of ngrams of length n\"\"\"\n",
    "        return set(text[i:i+n] for i in range(len(text)-n+1))\n",
    "\n",
    "\n",
    "    def ngk_calc(self, doc1, doc2, n):\n",
    "        sd1 = self.create_ngrams(doc1, n)\n",
    "        sd2 = self.create_ngrams(doc2, n)\n",
    "        #print sd1\n",
    "        #print sd2\n",
    "        if len(sd1 | sd2) == 0:\n",
    "            return 1.0\n",
    "\n",
    "        return len(sd1 & sd2) * 1.0 / len(sd1 | sd2)\n",
    "    \n",
    "    def calc_gram_mat(self, X, Y=None):        \n",
    "        sym = False\n",
    "        if Y is None:\n",
    "            sym = True\n",
    "            Y = X\n",
    "        n = len(X)\n",
    "        m = len(Y)\n",
    "        gram_matrix = np.zeros(shape=(n,m))\n",
    "        for i in range(n):\n",
    "            for j in range(m):\n",
    "                if sym and j < i:  # using symetry\n",
    "                    continue               \n",
    "            \n",
    "                if (X[i],Y[j]) in self.cache_dict:\n",
    "                    gram_matrix[i][j] =  self.cache_dict[(X[i],Y[j])]\n",
    "                    if sym: \n",
    "                        gram_matrix[j][i] = self.cache_dict[(X[i],Y[j])]\n",
    "                else:\n",
    "                    res = self.ngk_calc(X[i],Y[j], self.k)\n",
    "                    gram_matrix[i][j] =  res\n",
    "                    if sym:\n",
    "                        gram_matrix[j][i] = res\n",
    "                    self.cache_dict[(X[i],Y[j])] = res\n",
    "                    if sym:\n",
    "                        self.cache_dict[(Y[j],X[i])] = res\n",
    "        return gram_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SSK kernel implementation as proposed by [2] and copied from: https://github.com/muggin/string-kernels/blob/master/src/ssk_kernel.py\n",
    "\n",
    "import math\n",
    "import itertools as iter\n",
    "import numpy as np\n",
    "\n",
    "from string import lowercase\n",
    "\n",
    "class SskKernel:\n",
    "    def __init__(self, k, l):\n",
    "        self.k = k\n",
    "        self.l = l\n",
    "        #dictionary with the cached results of kernel evaluation\n",
    "        self.cache_dict = {}\n",
    "        \n",
    "    def ssk_calc(self, s, t, k, l):        \n",
    "        \"\"\"\n",
    "        Recursive SSK implementation.\n",
    "        :param s: document #1\n",
    "        :param t: document #2\n",
    "        :param k: subsequence length\n",
    "        :param l: weight decay (lambda)\n",
    "        :return: similarity of given documents\n",
    "        return:\n",
    "        \"\"\"\n",
    "        K_prime = self._compute_K_prime(s, t, k, l)\n",
    "        K_st = self._compute_K(s, t, k, l, K_prime)\n",
    "\n",
    "        K_prime = self._compute_K_prime(s, s, k, l)\n",
    "        K_ss = self._compute_K(s, s, k, l, K_prime)\n",
    "\n",
    "        K_prime = self._compute_K_prime(t, t, k, l)\n",
    "        K_tt = self._compute_K(t, t, k, l, K_prime)\n",
    "\n",
    "        denominator = math.sqrt(K_ss * K_tt) if K_ss * K_tt else 10e-20\n",
    "        return K_st / denominator\n",
    "\n",
    "\n",
    "    def _compute_K(self, s, t, k, l, K_prime):\n",
    "        \"\"\"\n",
    "        Compute and return the K in a recursive manner using precomputed K'\n",
    "        \"\"\"\n",
    "        K_val = 0\n",
    "\n",
    "        for m in xrange(len(s)+1):\n",
    "            if min(len(s[:m]), len(t)) < k:\n",
    "                continue\n",
    "\n",
    "            K_val += l**2 * sum([K_prime[k-1][len(s[:m])-1][j] for j in self._find_all_char_indices(s[m-1], t)])\n",
    "\n",
    "        return K_val\n",
    "\n",
    "\n",
    "    def _compute_K_prime(self, s, t, k, l):\n",
    "        \"\"\"\n",
    "        Compute and return K' using the efficient DP algorithm (K'')\n",
    "        \"\"\"\n",
    "        K_prime = np.ones((k, len(s)+1, len(t)+1))\n",
    "        K_dprime = np.zeros((k, len(s)+1, len(t)+1))\n",
    "\n",
    "        for i in xrange(1, k):\n",
    "            for m in xrange(len(s)+1):\n",
    "                for n in xrange(len(t)+1):\n",
    "                    if min(m, n) < i:\n",
    "                        K_prime[i][m][n] = 0\n",
    "                        continue\n",
    "\n",
    "                    if s[m-1] != t[n-1]:\n",
    "                        K_dprime[i][m][n] = l*K_dprime[i][m][n-1]\n",
    "                    else:\n",
    "                        K_dprime[i][m][n] = l*(K_dprime[i][m][n-1] + l*K_prime[i-1][m-1][n-1])\n",
    "\n",
    "                    K_prime[i][m][n] = l*K_prime[i][m-1][n] + K_dprime[i][m][n]\n",
    "\n",
    "        return K_prime\n",
    "\n",
    "    def _find_all_char_indices(self, char, string):\n",
    "        return [idx for idx, ltr in enumerate(string) if ltr == char]\n",
    "\n",
    "    def calc_gram_mat(self, X, Y=None):\n",
    "        sym = False\n",
    "        if Y is None:\n",
    "            sym = True\n",
    "            Y = X\n",
    "        n = len(X)\n",
    "        m = len(Y)\n",
    "        gram_matrix = np.zeros(shape=(n,m))\n",
    "        for i in range(n):\n",
    "            for j in range(m):\n",
    "                if sym and j < i:  # using symetry\n",
    "                    continue               \n",
    "            \n",
    "                if (X[i],Y[j]) in self.cache_dict:\n",
    "                    gram_matrix[i][j] =  self.cache_dict[(X[i],Y[j])]\n",
    "                    if sym: \n",
    "                        gram_matrix[j][i] = self.cache_dict[(X[i],Y[j])]\n",
    "                else:\n",
    "                    res = self.ssk_calc(X[i],Y[j], self.k, self.l)\n",
    "                    gram_matrix[i][j] =  res\n",
    "                    if sym:\n",
    "                        gram_matrix[j][i] = res\n",
    "                    self.cache_dict[(X[i],Y[j])] = res\n",
    "                    if sym:\n",
    "                        self.cache_dict[(Y[j],X[i])] = res\n",
    "        return gram_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For our datasets using small experiments we have discovered that $n=3$ is a good estimation of the best value for $n$ , then we will explore around this value $n = (2,3,4)$ and in order to cover more or less extreme and central values for $\\lambda$ we will explore $\\lambda = (0.01,0.25,0.5,0.75,0.99)$. Furthermore, using the same argument as with $\\lambda$ we will vary hyperparameter C as $C = (2^{-10},2^{-5},2^{0},2^{5},2^{10})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in order to make results easier, we will use the same technique as [1] and\n",
    "#vary only one of the parameters (lambda or n)\n",
    "\n",
    "#kernels for n = 3 constant\n",
    "#SSK kernels with n = 3 constant , lambda = (0.01,0.25,0.5,0.75,0.99)\n",
    "ssk_3_01 = SskKernel(3,0.01)\n",
    "ssk_3_25 = SskKernel(3,0.25)\n",
    "ssk_3_50 = SskKernel(3,0.5)\n",
    "ssk_3_75 = SskKernel(3,0.75)\n",
    "ssk_3_99 = SskKernel(3,0.99)\n",
    "#NGK kernel with n = 3 constant\n",
    "ngk_3 = NgkKernel(3)\n",
    "\n",
    "#kernels for lambda = 0.5 constant\n",
    "#SSK kernels with n = (2,3,4), lambda = 0.5 constant\n",
    "ssk_2_50 = SskKernel(2,0.5)\n",
    "#ssk_3_50 = SskKernel(3,0.5) (already defined and can be reused)\n",
    "ssk_4_50 = SskKernel(4,0.5)\n",
    "#NGK kernel with n = (2,3,4)\n",
    "ngk_2 = NgkKernel(2) \n",
    "#ngk_3 = NgkKernel(3) (already defined and can be reused)\n",
    "ngk_4 = NgkKernel(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting time:  2018-03-30 23:13:35.316350\n",
      "clf 0 ssk 3 01=> mean:  0.751  std:  0.05717516943569121\n",
      "clf 0 ssk 3 25=> mean:  0.7809999999999999  std:  0.04270831300812524\n",
      "clf 0 ssk 3 50=> mean:  0.7825  std:  0.031741140496207756\n",
      "clf 0 ssk 3 75=> mean:  0.7295  std:  0.03871046370169184\n",
      "clf 0 ssk 3 99=> mean:  0.6725000000000001  std:  0.03181980515339465\n",
      "clf 0 ssk 2 50=> mean:  0.769  std:  0.02839894364232585\n",
      "clf 0 ssk 4 50=> mean:  0.6595000000000001  std:  0.08076818680644007\n",
      "clf 0 ngk 2=> mean:  0.7710000000000001  std:  0.02799999999999998\n",
      "clf 0 ngk 3=> mean:  0.758  std:  0.07311634564172363\n",
      "clf 0 ngk 4=> mean:  0.674  std:  0.09910348127084134\n",
      "finishing time:  2018-03-31 01:33:02.309039\n"
     ]
    }
   ],
   "source": [
    "#Training all the kernels for C=2^-10\n",
    "print \"starting time: \" , datetime.datetime.now()\n",
    "\n",
    "clf_0_ssk_3_01 = SVC(kernel='precomputed',C=np.power(2.0,-10))\n",
    "gram_mat = ssk_3_01.calc_gram_mat(train)\n",
    "clf_0_ssk_3_01.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_0_ssk_3_01, gram_mat, target, cv=5)\n",
    "print \"clf 0 ssk 3 01=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_0_ssk_3_25 = SVC(kernel='precomputed',C=np.power(2.0,-10))\n",
    "gram_mat = ssk_3_25.calc_gram_mat(train)\n",
    "clf_0_ssk_3_25.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_0_ssk_3_25, gram_mat, target, cv=5)\n",
    "print \"clf 0 ssk 3 25=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_0_ssk_3_50 = SVC(kernel='precomputed',C=np.power(2.0,-10))\n",
    "gram_mat = ssk_3_50.calc_gram_mat(train)\n",
    "clf_0_ssk_3_50.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_0_ssk_3_50, gram_mat, target, cv=5)\n",
    "print \"clf 0 ssk 3 50=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_0_ssk_3_75 = SVC(kernel='precomputed',C=np.power(2.0,-10))\n",
    "gram_mat = ssk_3_75.calc_gram_mat(train)\n",
    "clf_0_ssk_3_75.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_0_ssk_3_75, gram_mat, target, cv=5)\n",
    "print \"clf 0 ssk 3 75=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_0_ssk_3_99 = SVC(kernel='precomputed',C=np.power(2.0,-10))\n",
    "gram_mat = ssk_3_99.calc_gram_mat(train)\n",
    "clf_0_ssk_3_99.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_0_ssk_3_99, gram_mat, target, cv=5)\n",
    "print \"clf 0 ssk 3 99=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_0_ssk_2_50 = SVC(kernel='precomputed',C=np.power(2.0,-10))\n",
    "gram_mat = ssk_2_50.calc_gram_mat(train)\n",
    "clf_0_ssk_2_50.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_0_ssk_2_50, gram_mat, target, cv=5)\n",
    "print \"clf 0 ssk 2 50=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_0_ssk_4_50 = SVC(kernel='precomputed',C=np.power(2.0,-10))\n",
    "gram_mat = ssk_4_50.calc_gram_mat(train)\n",
    "clf_0_ssk_4_50.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_0_ssk_4_50, gram_mat, target, cv=5)\n",
    "print \"clf 0 ssk 4 50=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_0_ngk_2 = SVC(kernel='precomputed',C=np.power(2.0,-10))\n",
    "gram_mat = ngk_2.calc_gram_mat(train)\n",
    "clf_0_ngk_2.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_0_ngk_2, gram_mat, target, cv=5)\n",
    "print \"clf 0 ngk 2=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_0_ngk_3 = SVC(kernel='precomputed',C=np.power(2.0,-10))\n",
    "gram_mat = ngk_3.calc_gram_mat(train)\n",
    "clf_0_ngk_3.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_0_ngk_3, gram_mat, target, cv=5)\n",
    "print \"clf 0 ngk 3=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_0_ngk_4 = SVC(kernel='precomputed',C=np.power(2.0,-10))\n",
    "gram_mat = ngk_4.calc_gram_mat(train)\n",
    "clf_0_ngk_4.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_0_ngk_4, gram_mat, target, cv=5)\n",
    "print \"clf 0 ngk 4=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "print \"finishing time: \" , datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf 1 ssk 3 01=> mean:  0.751  std:  0.05717516943569121\n",
      "clf 1 ssk 3 25=> mean:  0.7809999999999999  std:  0.04270831300812524\n",
      "clf 1 ssk 3 50=> mean:  0.7825  std:  0.031741140496207756\n",
      "clf 1 ssk 3 75=> mean:  0.7295  std:  0.03871046370169184\n",
      "clf 1 ssk 3 99=> mean:  0.6725000000000001  std:  0.03181980515339465\n",
      "clf 1 ssk 2 50=> mean:  0.77  std:  0.027658633371878644\n",
      "clf 1 ssk 4 50=> mean:  0.6595000000000001  std:  0.08076818680644007\n",
      "clf 1 ngk 2=> mean:  0.7710000000000001  std:  0.02799999999999998\n",
      "clf 1 ngk 3=> mean:  0.758  std:  0.07311634564172363\n",
      "clf 1 ngk 4=> mean:  0.674  std:  0.09910348127084134\n"
     ]
    }
   ],
   "source": [
    "#Training all the kernels for C=2^-5\n",
    "clf_1_ssk_3_01 = SVC(kernel='precomputed',C=np.power(2.0,-5))\n",
    "gram_mat = ssk_3_01.calc_gram_mat(train)\n",
    "clf_1_ssk_3_01.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_1_ssk_3_01, gram_mat, target, cv=5)\n",
    "print \"clf 1 ssk 3 01=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_1_ssk_3_25 = SVC(kernel='precomputed',C=np.power(2.0,-5))\n",
    "gram_mat = ssk_3_25.calc_gram_mat(train)\n",
    "clf_1_ssk_3_25.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_1_ssk_3_25, gram_mat, target, cv=5)\n",
    "print \"clf 1 ssk 3 25=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_1_ssk_3_50 = SVC(kernel='precomputed',C=np.power(2.0,-5))\n",
    "gram_mat = ssk_3_50.calc_gram_mat(train)\n",
    "clf_1_ssk_3_50.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_1_ssk_3_50, gram_mat, target, cv=5)\n",
    "print \"clf 1 ssk 3 50=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_1_ssk_3_75 = SVC(kernel='precomputed',C=np.power(2.0,-5))\n",
    "gram_mat = ssk_3_75.calc_gram_mat(train)\n",
    "clf_1_ssk_3_75.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_1_ssk_3_75, gram_mat, target, cv=5)\n",
    "print \"clf 1 ssk 3 75=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_1_ssk_3_99 = SVC(kernel='precomputed',C=np.power(2.0,-5))\n",
    "gram_mat = ssk_3_99.calc_gram_mat(train)\n",
    "clf_1_ssk_3_99.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_1_ssk_3_99, gram_mat, target, cv=5)\n",
    "print \"clf 1 ssk 3 99=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_1_ssk_2_50 = SVC(kernel='precomputed',C=np.power(2.0,-5))\n",
    "gram_mat = ssk_2_50.calc_gram_mat(train)\n",
    "clf_1_ssk_2_50.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_1_ssk_2_50, gram_mat, target, cv=5)\n",
    "print \"clf 1 ssk 2 50=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_1_ssk_4_50 = SVC(kernel='precomputed',C=np.power(2.0,-5))\n",
    "gram_mat = ssk_4_50.calc_gram_mat(train)\n",
    "clf_1_ssk_4_50.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_1_ssk_4_50, gram_mat, target, cv=5)\n",
    "print \"clf 1 ssk 4 50=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_1_ngk_2 = SVC(kernel='precomputed',C=np.power(2.0,-5))\n",
    "gram_mat = ngk_2.calc_gram_mat(train)\n",
    "clf_1_ngk_2.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_1_ngk_2, gram_mat, target, cv=5)\n",
    "print \"clf 1 ngk 2=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_1_ngk_3 = SVC(kernel='precomputed',C=np.power(2.0,-5))\n",
    "gram_mat = ngk_3.calc_gram_mat(train)\n",
    "clf_1_ngk_3.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_1_ngk_3, gram_mat, target, cv=5)\n",
    "print \"clf 1 ngk 3=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_1_ngk_4 = SVC(kernel='precomputed',C=np.power(2.0,-5))\n",
    "gram_mat = ngk_4.calc_gram_mat(train)\n",
    "clf_1_ngk_4.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_1_ngk_4, gram_mat, target, cv=5)\n",
    "print \"clf 1 ngk 4=> mean: \", scores.mean(), \" std: \", scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf 2 ssk 3 01=> mean:  0.8394999999999999  std:  0.016000000000000028\n",
      "clf 2 ssk 3 25=> mean:  0.8554999999999999  std:  0.017916472867168916\n",
      "clf 2 ssk 3 50=> mean:  0.8605  std:  0.025169425897306443\n",
      "clf 2 ssk 3 75=> mean:  0.8605  std:  0.023313086453749545\n",
      "clf 2 ssk 3 99=> mean:  0.8535  std:  0.02332380757938119\n",
      "clf 2 ssk 2 50=> mean:  0.8530000000000001  std:  0.025169425897306447\n",
      "clf 2 ssk 4 50=> mean:  0.8075000000000001  std:  0.03350373113550193\n",
      "clf 2 ngk 2=> mean:  0.8710000000000001  std:  0.024779023386727717\n",
      "clf 2 ngk 3=> mean:  0.845  std:  0.022248595461286994\n",
      "clf 2 ngk 4=> mean:  0.785  std:  0.027973201461398752\n"
     ]
    }
   ],
   "source": [
    "#Training all the kernels for C=2^0\n",
    "clf_2_ssk_3_01 = SVC(kernel='precomputed')\n",
    "gram_mat = ssk_3_01.calc_gram_mat(train)\n",
    "clf_2_ssk_3_01.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_2_ssk_3_01, gram_mat, target, cv=5)\n",
    "print \"clf 2 ssk 3 01=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_2_ssk_3_25 = SVC(kernel='precomputed')\n",
    "gram_mat = ssk_3_25.calc_gram_mat(train)\n",
    "clf_2_ssk_3_25.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_2_ssk_3_25, gram_mat, target, cv=5)\n",
    "print \"clf 2 ssk 3 25=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_2_ssk_3_50 = SVC(kernel='precomputed')\n",
    "gram_mat = ssk_3_50.calc_gram_mat(train)\n",
    "clf_2_ssk_3_50.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_2_ssk_3_50, gram_mat, target, cv=5)\n",
    "print \"clf 2 ssk 3 50=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_2_ssk_3_75 = SVC(kernel='precomputed')\n",
    "gram_mat = ssk_3_75.calc_gram_mat(train)\n",
    "clf_2_ssk_3_75.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_2_ssk_3_75, gram_mat, target, cv=5)\n",
    "print \"clf 2 ssk 3 75=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_2_ssk_3_99 = SVC(kernel='precomputed')\n",
    "gram_mat = ssk_3_99.calc_gram_mat(train)\n",
    "clf_2_ssk_3_99.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_2_ssk_3_99, gram_mat, target, cv=5)\n",
    "print \"clf 2 ssk 3 99=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_2_ssk_2_50 = SVC(kernel='precomputed')\n",
    "gram_mat = ssk_2_50.calc_gram_mat(train)\n",
    "clf_2_ssk_2_50.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_2_ssk_2_50, gram_mat, target, cv=5)\n",
    "print \"clf 2 ssk 2 50=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_2_ssk_4_50 = SVC(kernel='precomputed')\n",
    "gram_mat = ssk_4_50.calc_gram_mat(train)\n",
    "clf_2_ssk_4_50.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_2_ssk_4_50, gram_mat, target, cv=5)\n",
    "print \"clf 2 ssk 4 50=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_2_ngk_2 = SVC(kernel='precomputed')\n",
    "gram_mat = ngk_2.calc_gram_mat(train)\n",
    "clf_2_ngk_2.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_2_ngk_2, gram_mat, target, cv=5)\n",
    "print \"clf 2 ngk 2=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_2_ngk_3 = SVC(kernel='precomputed')\n",
    "gram_mat = ngk_3.calc_gram_mat(train)\n",
    "clf_2_ngk_3.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_2_ngk_3, gram_mat, target, cv=5)\n",
    "print \"clf 2 ngk 3=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_2_ngk_4 = SVC(kernel='precomputed')\n",
    "gram_mat = ngk_4.calc_gram_mat(train)\n",
    "clf_2_ngk_4.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_2_ngk_4, gram_mat, target, cv=5)\n",
    "print \"clf 2 ngk 4=> mean: \", scores.mean(), \" std: \", scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf 3 ssk 3 01=> mean:  0.8195  std:  0.0183983694929741\n",
      "clf 3 ssk 3 25=> mean:  0.834  std:  0.01617096162879625\n",
      "clf 3 ssk 3 50=> mean:  0.842  std:  0.023632604596192947\n",
      "clf 3 ssk 3 75=> mean:  0.8355  std:  0.024155744658362354\n",
      "clf 3 ssk 3 99=> mean:  0.834  std:  0.022169799277395357\n",
      "clf 3 ssk 2 50=> mean:  0.843  std:  0.031953090617340904\n",
      "clf 3 ssk 4 50=> mean:  0.8140000000000001  std:  0.03132890039564108\n",
      "clf 3 ngk 2=> mean:  0.875  std:  0.02138924963620745\n",
      "clf 3 ngk 3=> mean:  0.8450000000000001  std:  0.02079663434308543\n",
      "clf 3 ngk 4=> mean:  0.7875  std:  0.030454884665682126\n"
     ]
    }
   ],
   "source": [
    "#Training all the kernels for C=2^5\n",
    "clf_3_ssk_3_01 = SVC(kernel='precomputed',C=np.power(2.0,5))\n",
    "gram_mat = ssk_3_01.calc_gram_mat(train)\n",
    "clf_3_ssk_3_01.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_3_ssk_3_01, gram_mat, target, cv=5)\n",
    "print \"clf 3 ssk 3 01=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_3_ssk_3_25 = SVC(kernel='precomputed',C=np.power(2.0,5))\n",
    "gram_mat = ssk_3_25.calc_gram_mat(train)\n",
    "clf_3_ssk_3_25.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_3_ssk_3_25, gram_mat, target, cv=5)\n",
    "print \"clf 3 ssk 3 25=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_3_ssk_3_50 = SVC(kernel='precomputed',C=np.power(2.0,5))\n",
    "gram_mat = ssk_3_50.calc_gram_mat(train)\n",
    "clf_3_ssk_3_50.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_3_ssk_3_50, gram_mat, target, cv=5)\n",
    "print \"clf 3 ssk 3 50=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_3_ssk_3_75 = SVC(kernel='precomputed',C=np.power(2.0,5))\n",
    "gram_mat = ssk_3_75.calc_gram_mat(train)\n",
    "clf_3_ssk_3_75.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_3_ssk_3_75, gram_mat, target, cv=5)\n",
    "print \"clf 3 ssk 3 75=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_3_ssk_3_99 = SVC(kernel='precomputed',C=np.power(2.0,5))\n",
    "gram_mat = ssk_3_99.calc_gram_mat(train)\n",
    "clf_3_ssk_3_99.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_3_ssk_3_99, gram_mat, target, cv=5)\n",
    "print \"clf 3 ssk 3 99=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_3_ssk_2_50 = SVC(kernel='precomputed',C=np.power(2.0,5))\n",
    "gram_mat = ssk_2_50.calc_gram_mat(train)\n",
    "clf_3_ssk_2_50.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_3_ssk_2_50, gram_mat, target, cv=5)\n",
    "print \"clf 3 ssk 2 50=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_3_ssk_4_50 = SVC(kernel='precomputed',C=np.power(2.0,5))\n",
    "gram_mat = ssk_4_50.calc_gram_mat(train)\n",
    "clf_3_ssk_4_50.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_3_ssk_4_50, gram_mat, target, cv=5)\n",
    "print \"clf 3 ssk 4 50=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_3_ngk_2 = SVC(kernel='precomputed',C=np.power(2.0,5))\n",
    "gram_mat = ngk_2.calc_gram_mat(train)\n",
    "clf_3_ngk_2.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_3_ngk_2, gram_mat, target, cv=5)\n",
    "print \"clf 3 ngk 2=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_3_ngk_3 = SVC(kernel='precomputed',C=np.power(2.0,5))\n",
    "gram_mat = ngk_3.calc_gram_mat(train)\n",
    "clf_3_ngk_3.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_3_ngk_3, gram_mat, target, cv=5)\n",
    "print \"clf 3 ngk 3=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_3_ngk_4 = SVC(kernel='precomputed',C=np.power(2.0,5))\n",
    "gram_mat = ngk_4.calc_gram_mat(train)\n",
    "clf_3_ngk_4.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_3_ngk_4, gram_mat, target, cv=5)\n",
    "print \"clf 3 ngk 4=> mean: \", scores.mean(), \" std: \", scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting time:  2018-03-31 01:34:27.207629\n",
      "clf 3 ssk 3 01=> mean:  0.8155000000000001  std:  0.021702534414210693\n",
      "clf 3 ssk 3 25=> mean:  0.8334999999999999  std:  0.013928388277184138\n",
      "clf 3 ssk 3 50=> mean:  0.843  std:  0.02420743687382039\n",
      "clf 3 ssk 3 75=> mean:  0.8355  std:  0.024155744658362354\n",
      "clf 3 ssk 3 99=> mean:  0.834  std:  0.022169799277395357\n",
      "clf 3 ssk 2 50=> mean:  0.8119999999999999  std:  0.010653637876331251\n",
      "clf 3 ssk 4 50=> mean:  0.8140000000000001  std:  0.03132890039564108\n",
      "clf 3 ngk 2=> mean:  0.875  std:  0.02138924963620745\n",
      "clf 3 ngk 3=> mean:  0.8450000000000001  std:  0.02079663434308543\n",
      "clf 3 ngk 4=> mean:  0.7875  std:  0.030454884665682126\n",
      "finishing time:  2018-03-31 01:35:11.329914\n"
     ]
    }
   ],
   "source": [
    "#Training all the kernels for C=2^10\n",
    "print \"starting time: \" , datetime.datetime.now()\n",
    "\n",
    "clf_4_ssk_3_01 = SVC(kernel='precomputed',C=np.power(2.0,10))\n",
    "gram_mat = ssk_3_01.calc_gram_mat(train)\n",
    "clf_4_ssk_3_01.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_4_ssk_3_01, gram_mat, target, cv=5)\n",
    "print \"clf 3 ssk 3 01=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_4_ssk_3_25 = SVC(kernel='precomputed',C=np.power(2.0,10))\n",
    "gram_mat = ssk_3_25.calc_gram_mat(train)\n",
    "clf_4_ssk_3_25.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_4_ssk_3_25, gram_mat, target, cv=5)\n",
    "print \"clf 3 ssk 3 25=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_4_ssk_3_50 = SVC(kernel='precomputed',C=np.power(2.0,10))\n",
    "gram_mat = ssk_3_50.calc_gram_mat(train)\n",
    "clf_4_ssk_3_50.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_4_ssk_3_50, gram_mat, target, cv=5)\n",
    "print \"clf 3 ssk 3 50=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_4_ssk_3_75 = SVC(kernel='precomputed',C=np.power(2.0,10))\n",
    "gram_mat = ssk_3_75.calc_gram_mat(train)\n",
    "clf_4_ssk_3_75.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_4_ssk_3_75, gram_mat, target, cv=5)\n",
    "print \"clf 3 ssk 3 75=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_4_ssk_3_99 = SVC(kernel='precomputed',C=np.power(2.0,10))\n",
    "gram_mat = ssk_3_99.calc_gram_mat(train)\n",
    "clf_4_ssk_3_99.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_4_ssk_3_99, gram_mat, target, cv=5)\n",
    "print \"clf 3 ssk 3 99=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_4_ssk_2_50 = SVC(kernel='precomputed',C=np.power(2.0,10))\n",
    "gram_mat = ssk_2_50.calc_gram_mat(train)\n",
    "clf_4_ssk_2_50.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_4_ssk_2_50, gram_mat, target, cv=5)\n",
    "print \"clf 3 ssk 2 50=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_4_ssk_4_50 = SVC(kernel='precomputed',C=np.power(2.0,10))\n",
    "gram_mat = ssk_4_50.calc_gram_mat(train)\n",
    "clf_4_ssk_4_50.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_4_ssk_4_50, gram_mat, target, cv=5)\n",
    "print \"clf 3 ssk 4 50=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_4_ngk_2 = SVC(kernel='precomputed',C=np.power(2.0,10))\n",
    "gram_mat = ngk_2.calc_gram_mat(train)\n",
    "clf_4_ngk_2.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_4_ngk_2, gram_mat, target, cv=5)\n",
    "print \"clf 3 ngk 2=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_4_ngk_3 = SVC(kernel='precomputed',C=np.power(2.0,10))\n",
    "gram_mat = ngk_3.calc_gram_mat(train)\n",
    "clf_4_ngk_3.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_4_ngk_3, gram_mat, target, cv=5)\n",
    "print \"clf 3 ngk 3=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "clf_4_ngk_4 = SVC(kernel='precomputed',C=np.power(2.0,10))\n",
    "gram_mat = ngk_4.calc_gram_mat(train)\n",
    "clf_4_ngk_4.fit(gram_mat,target)\n",
    "scores = cross_val_score(clf_4_ngk_4, gram_mat, target, cv=5)\n",
    "print \"clf 3 ngk 4=> mean: \", scores.mean(), \" std: \", scores.std()\n",
    "\n",
    "print \"finishing time: \" , datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d)\n",
    "\n",
    "##### i. The Summarize of the results are presented in the following table ( In red the best results for SSK and in blue the best results for NGK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;border-color:#ccc;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#ccc;color:#333;background-color:#fff;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#ccc;color:#333;background-color:#f0f0f0;}\n",
    ".tg .tg-u2wy{background-color:#f9f9f9;font-weight:bold;border-color:inherit;vertical-align:top}\n",
    ".tg .tg-zx9n{background-color:#f9f9f9;font-weight:bold;font-family:Arial, Helvetica, sans-serif !important;;border-color:inherit;vertical-align:top}\n",
    ".tg .tg-dc35{background-color:#f9f9f9;border-color:inherit;vertical-align:top}\n",
    ".tg .tg-us36{border-color:inherit;vertical-align:top}\n",
    ".tg .tg-c0ir{background-color:#32cb00;border-color:inherit;vertical-align:top}\n",
    ".tg .tg-p8bj{font-weight:bold;border-color:inherit;vertical-align:top}\n",
    ".tg .tg-7btt{font-weight:bold;border-color:inherit;text-align:center;vertical-align:top}\n",
    ".tg .tg-80xr{background-color:#00009b;border-color:inherit;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-p8bj\" rowspan=\"2\">Kernel<br></th>\n",
    "    <th class=\"tg-7btt\" rowspan=\"2\">C</th>\n",
    "    <th class=\"tg-7btt\" rowspan=\"2\">&lambda;<br></th>\n",
    "    <th class=\"tg-p8bj\" rowspan=\"2\">n</th>\n",
    "    <th class=\"tg-p8bj\" colspan=\"2\">5-fold cross validation<br></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-u2wy\">Mean<br></td>\n",
    "    <td class=\"tg-u2wy\">Std<br></td>\n",
    "  </tr>\n",
    "  <tr bgcolor=\"#FF0000\" fontcolor=\"#FF0000\">\n",
    "    <td class=\"tg-p8bj\" rowspan=\"7\">SSK</td>\n",
    "    <td class=\"tg-us36\">$2^{-10}$</td>\n",
    "    <td class=\"tg-us36\">0.01</td>\n",
    "    <td class=\"tg-us36\">3<br></td>\n",
    "    <td class=\"tg-us36\">0.751</td>\n",
    "    <td class=\"tg-us36\">0.057</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-dc35\">$2^{-10}$</td>\n",
    "    <td class=\"tg-dc35\">0.25</td>\n",
    "    <td class=\"tg-dc35\">3</td>\n",
    "    <td class=\"tg-dc35\">0.780</td>\n",
    "    <td class=\"tg-dc35\">0.042</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-us36\">$2^{-10}$</td>\n",
    "    <td class=\"tg-us36\">0.5</td>\n",
    "    <td class=\"tg-us36\">3</td>\n",
    "    <td class=\"tg-us36\">0.782</td>\n",
    "    <td class=\"tg-us36\">0.031</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-dc35\">$2^{-10}$</td>\n",
    "    <td class=\"tg-dc35\">0.75</td>\n",
    "    <td class=\"tg-dc35\">3</td>\n",
    "    <td class=\"tg-dc35\">0.729</td>\n",
    "    <td class=\"tg-dc35\">0.038</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-us36\">$2^{-10}$</td>\n",
    "    <td class=\"tg-us36\">0.99</td>\n",
    "    <td class=\"tg-us36\">3</td>\n",
    "    <td class=\"tg-us36\">0.672</td>\n",
    "    <td class=\"tg-us36\">0.031</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-dc35\">$2^{-10}$</td>\n",
    "    <td class=\"tg-dc35\">0.5</td>\n",
    "    <td class=\"tg-dc35\">2</td>\n",
    "    <td class=\"tg-dc35\">0.769</td>\n",
    "    <td class=\"tg-dc35\">0.028</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-c0ir\">$2^{-10}$</td>\n",
    "    <td class=\"tg-c0ir\">0.5</td>\n",
    "    <td class=\"tg-c0ir\">4<br></td>\n",
    "    <td class=\"tg-c0ir\">0.659</td>\n",
    "    <td class=\"tg-c0ir\">0.080</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-zx9n\" rowspan=\"3\">NGK</td>\n",
    "    <td class=\"tg-dc35\">$2^{-10}$</td>\n",
    "    <td class=\"tg-dc35\">NA<br></td>\n",
    "    <td class=\"tg-dc35\">2</td>\n",
    "    <td class=\"tg-dc35\">0.771</td>\n",
    "    <td class=\"tg-dc35\">0.027</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-us36\">$2^{-10}$</td>\n",
    "    <td class=\"tg-us36\">NA</td>\n",
    "    <td class=\"tg-us36\">3</td>\n",
    "    <td class=\"tg-us36\">0.758</td>\n",
    "    <td class=\"tg-us36\">0.073</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-80xr\">$2^{-10}$</td>\n",
    "    <td class=\"tg-80xr\">NA</td>\n",
    "    <td class=\"tg-80xr\">4</td>\n",
    "    <td class=\"tg-80xr\">0.674</td>\n",
    "    <td class=\"tg-80xr\">0.099</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td class=\"tg-p8bj\" rowspan=\"7\">SSK</td>\n",
    "    <td class=\"tg-us36\">$2^{-5}$</td>\n",
    "    <td class=\"tg-us36\">0.01</td>\n",
    "    <td class=\"tg-us36\">3<br></td>\n",
    "    <td class=\"tg-us36\">0.751</td>\n",
    "    <td class=\"tg-us36\">0.057</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-dc35\">$2^{-5}$</td>\n",
    "    <td class=\"tg-dc35\">0.25</td>\n",
    "    <td class=\"tg-dc35\">3</td>\n",
    "    <td class=\"tg-dc35\">0.780</td>\n",
    "    <td class=\"tg-dc35\">0.042</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-us36\">$2^{-5}$</td>\n",
    "    <td class=\"tg-us36\">0.5</td>\n",
    "    <td class=\"tg-us36\">3</td>\n",
    "    <td class=\"tg-us36\">0.782</td>\n",
    "    <td class=\"tg-us36\">0.031</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-dc35\">$2^{-5}$</td>\n",
    "    <td class=\"tg-dc35\">0.75</td>\n",
    "    <td class=\"tg-dc35\">3</td>\n",
    "    <td class=\"tg-dc35\">0.729</td>\n",
    "    <td class=\"tg-dc35\">0.038</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-us36\">$2^{-5}$</td>\n",
    "    <td class=\"tg-us36\">0.99</td>\n",
    "    <td class=\"tg-us36\">3</td>\n",
    "    <td class=\"tg-us36\">0.672</td>\n",
    "    <td class=\"tg-us36\">0.031</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-dc35\">$2^{-5}$</td>\n",
    "    <td class=\"tg-dc35\">0.5</td>\n",
    "    <td class=\"tg-dc35\">2</td>\n",
    "    <td class=\"tg-dc35\">0.769</td>\n",
    "    <td class=\"tg-dc35\">0.028</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-c0ir\">$2^{-5}$</td>\n",
    "    <td class=\"tg-c0ir\">0.5</td>\n",
    "    <td class=\"tg-c0ir\">4<br></td>\n",
    "    <td class=\"tg-c0ir\">0.659</td>\n",
    "    <td class=\"tg-c0ir\">0.080</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-zx9n\" rowspan=\"3\">NGK</td>\n",
    "    <td class=\"tg-dc35\">$2^{-5}$</td>\n",
    "    <td class=\"tg-dc35\">NA<br></td>\n",
    "    <td class=\"tg-dc35\">2</td>\n",
    "    <td class=\"tg-dc35\">0.771</td>\n",
    "    <td class=\"tg-dc35\">0.027</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-us36\">$2^{-5}$</td>\n",
    "    <td class=\"tg-us36\">NA</td>\n",
    "    <td class=\"tg-us36\">3</td>\n",
    "    <td class=\"tg-us36\">0.758</td>\n",
    "    <td class=\"tg-us36\">0.073</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-80xr\">$2^{-5}$</td>\n",
    "    <td class=\"tg-80xr\">NA</td>\n",
    "    <td class=\"tg-80xr\">4</td>\n",
    "    <td class=\"tg-80xr\">0.674</td>\n",
    "    <td class=\"tg-80xr\">0.099</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td class=\"tg-p8bj\" rowspan=\"7\">SSK</td>\n",
    "    <td class=\"tg-us36\">$2^{0}$</td>\n",
    "    <td class=\"tg-us36\">0.01</td>\n",
    "    <td class=\"tg-us36\">3<br></td>\n",
    "    <td class=\"tg-us36\">0.839</td>\n",
    "    <td class=\"tg-us36\">0.016</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-dc35\">$2^{0}$</td>\n",
    "    <td class=\"tg-dc35\">0.25</td>\n",
    "    <td class=\"tg-dc35\">3</td>\n",
    "    <td class=\"tg-dc35\">0.855</td>\n",
    "    <td class=\"tg-dc35\">0.017</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-us36\">$2^{0}$</td>\n",
    "    <td class=\"tg-us36\">0.5</td>\n",
    "    <td class=\"tg-us36\">3</td>\n",
    "    <td class=\"tg-us36\">0.860</td>\n",
    "    <td class=\"tg-us36\">0.025</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td bgcolor=\"#ff1a1a\">$2^{0}$</td>\n",
    "    <td bgcolor=\"#ff1a1a\">0.75</td>\n",
    "    <td bgcolor=\"#ff1a1a\">3</td>\n",
    "    <td bgcolor=\"#ff1a1a\">0.860</td>\n",
    "    <td bgcolor=\"#ff1a1a\">0.023</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-us36\">$2^{0}$</td>\n",
    "    <td class=\"tg-us36\">0.99</td>\n",
    "    <td class=\"tg-us36\">3</td>\n",
    "    <td class=\"tg-us36\">0.853</td>\n",
    "    <td class=\"tg-us36\">0.023</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-dc35\">$2^{0}$</td>\n",
    "    <td class=\"tg-dc35\">0.5</td>\n",
    "    <td class=\"tg-dc35\">2</td>\n",
    "    <td class=\"tg-dc35\">0.853</td>\n",
    "    <td class=\"tg-dc35\">0.025</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-c0ir\">$2^{0}$</td>\n",
    "    <td class=\"tg-c0ir\">0.5</td>\n",
    "    <td class=\"tg-c0ir\">4<br></td>\n",
    "    <td class=\"tg-c0ir\">0.807</td>\n",
    "    <td class=\"tg-c0ir\">0.033</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-zx9n\" rowspan=\"3\">NGK</td>\n",
    "    <td bgcolor=\"#3366ff\">$2^{0}$</td>\n",
    "    <td bgcolor=\"#3366ff\">NA<br></td>\n",
    "    <td bgcolor=\"#3366ff\">2</td>\n",
    "    <td bgcolor=\"#3366ff\">0.871</td>\n",
    "    <td bgcolor=\"#3366ff\">0.024</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-us36\">$2^{0}$</td>\n",
    "    <td class=\"tg-us36\">NA</td>\n",
    "    <td class=\"tg-us36\">3</td>\n",
    "    <td class=\"tg-us36\">0.845</td>\n",
    "    <td class=\"tg-us36\">0.022</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-80xr\">$2^{0}$</td>\n",
    "    <td class=\"tg-80xr\">NA</td>\n",
    "    <td class=\"tg-80xr\">4</td>\n",
    "    <td class=\"tg-80xr\">0.785</td>\n",
    "    <td class=\"tg-80xr\">0.027</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td class=\"tg-p8bj\" rowspan=\"7\">SSK</td>\n",
    "    <td class=\"tg-us36\">$2^{5}$</td>\n",
    "    <td class=\"tg-us36\">0.01</td>\n",
    "    <td class=\"tg-us36\">3<br></td>\n",
    "    <td class=\"tg-us36\">0.819</td>\n",
    "    <td class=\"tg-us36\">0.018</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-dc35\">$2^{5}$</td>\n",
    "    <td class=\"tg-dc35\">0.25</td>\n",
    "    <td class=\"tg-dc35\">3</td>\n",
    "    <td class=\"tg-dc35\">0.834</td>\n",
    "    <td class=\"tg-dc35\">0.016</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-us36\">$2^{5}$</td>\n",
    "    <td class=\"tg-us36\">0.5</td>\n",
    "    <td class=\"tg-us36\">3</td>\n",
    "    <td class=\"tg-us36\">0.842</td>\n",
    "    <td class=\"tg-us36\">0.023</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-dc35\">$2^{5}$</td>\n",
    "    <td class=\"tg-dc35\">0.75</td>\n",
    "    <td class=\"tg-dc35\">3</td>\n",
    "    <td class=\"tg-dc35\">0.835</td>\n",
    "    <td class=\"tg-dc35\">0.024</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-us36\">$2^{5}$</td>\n",
    "    <td class=\"tg-us36\">0.99</td>\n",
    "    <td class=\"tg-us36\">3</td>\n",
    "    <td class=\"tg-us36\">0.834</td>\n",
    "    <td class=\"tg-us36\">0.022</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-dc35\">$2^{5}$</td>\n",
    "    <td class=\"tg-dc35\">0.5</td>\n",
    "    <td class=\"tg-dc35\">2</td>\n",
    "    <td class=\"tg-dc35\">0.843</td>\n",
    "    <td class=\"tg-dc35\">0.031</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-c0ir\">$2^{5}$</td>\n",
    "    <td class=\"tg-c0ir\">0.5</td>\n",
    "    <td class=\"tg-c0ir\">4<br></td>\n",
    "    <td class=\"tg-c0ir\">0.814</td>\n",
    "    <td class=\"tg-c0ir\">0.031</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-zx9n\" rowspan=\"3\">NGK</td>\n",
    "    <td class=\"tg-dc35\">$2^{5}$</td>\n",
    "    <td class=\"tg-dc35\">NA<br></td>\n",
    "    <td class=\"tg-dc35\">2</td>\n",
    "    <td class=\"tg-dc35\">0.875</td>\n",
    "    <td class=\"tg-dc35\">0.021</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-us36\">$2^{5}$</td>\n",
    "    <td class=\"tg-us36\">NA</td>\n",
    "    <td class=\"tg-us36\">3</td>\n",
    "    <td class=\"tg-us36\">0.845</td>\n",
    "    <td class=\"tg-us36\">0.020</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-80xr\">$2^{5}$</td>\n",
    "    <td class=\"tg-80xr\">NA</td>\n",
    "    <td class=\"tg-80xr\">4</td>\n",
    "    <td class=\"tg-80xr\">0.787</td>\n",
    "    <td class=\"tg-80xr\">0.030</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td class=\"tg-p8bj\" rowspan=\"7\">SSK</td>\n",
    "    <td class=\"tg-us36\">$2^{10}$</td>\n",
    "    <td class=\"tg-us36\">0.01</td>\n",
    "    <td class=\"tg-us36\">3<br></td>\n",
    "    <td class=\"tg-us36\">0.815</td>\n",
    "    <td class=\"tg-us36\">0.021</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-dc35\">$2^{10}$</td>\n",
    "    <td class=\"tg-dc35\">0.25</td>\n",
    "    <td class=\"tg-dc35\">3</td>\n",
    "    <td class=\"tg-dc35\">0.833</td>\n",
    "    <td class=\"tg-dc35\">0.013</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-us36\">$2^{10}$</td>\n",
    "    <td class=\"tg-us36\">0.5</td>\n",
    "    <td class=\"tg-us36\">3</td>\n",
    "    <td class=\"tg-us36\">0.843</td>\n",
    "    <td class=\"tg-us36\">0.024</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-dc35\">$2^{10}$</td>\n",
    "    <td class=\"tg-dc35\">0.75</td>\n",
    "    <td class=\"tg-dc35\">3</td>\n",
    "    <td class=\"tg-dc35\">0.835</td>\n",
    "    <td class=\"tg-dc35\">0.024</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-us36\">$2^{10}$</td>\n",
    "    <td class=\"tg-us36\">0.99</td>\n",
    "    <td class=\"tg-us36\">3</td>\n",
    "    <td class=\"tg-us36\">0.834</td>\n",
    "    <td class=\"tg-us36\">0.022</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-dc35\">$2^{10}$</td>\n",
    "    <td class=\"tg-dc35\">0.5</td>\n",
    "    <td class=\"tg-dc35\">2</td>\n",
    "    <td class=\"tg-dc35\">0.811</td>\n",
    "    <td class=\"tg-dc35\">0.010</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-c0ir\">$2^{10}$</td>\n",
    "    <td class=\"tg-c0ir\">0.5</td>\n",
    "    <td class=\"tg-c0ir\">4<br></td>\n",
    "    <td class=\"tg-c0ir\">0.814</td>\n",
    "    <td class=\"tg-c0ir\">0.031</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-zx9n\" rowspan=\"3\">NGK</td>\n",
    "    <td class=\"tg-dc35\">$2^{10}$</td>\n",
    "    <td class=\"tg-dc35\">NA<br></td>\n",
    "    <td class=\"tg-dc35\">2</td>\n",
    "    <td class=\"tg-dc35\">0.875</td>\n",
    "    <td class=\"tg-dc35\">0.021</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-us36\">$2^{10}$</td>\n",
    "    <td class=\"tg-us36\">NA</td>\n",
    "    <td class=\"tg-us36\">3</td>\n",
    "    <td class=\"tg-us36\">0.845</td>\n",
    "    <td class=\"tg-us36\">0.020</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-80xr\">$2^{10}$</td>\n",
    "    <td class=\"tg-80xr\">NA</td>\n",
    "    <td class=\"tg-80xr\">4</td>\n",
    "    <td class=\"tg-80xr\">0.787</td>\n",
    "    <td class=\"tg-80xr\">0.030</td>\n",
    "  </tr>\n",
    "  \n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f84037de750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8403834710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Now we will evaluate the performance of the best parameters for both kernels\n",
    "bestSsk = ssk_3_75\n",
    "bestSskModel = clf_2_ssk_3_75\n",
    "bestNgk = ngk_2 = NgkKernel(2) \n",
    "bestNgKModel = clf_2_ngk_2\n",
    "\n",
    "ssk_gram = bestSsk.calc_gram_mat(prod, train)\n",
    "ngk_gram = bestNgk.calc_gram_mat(prod, train)\n",
    "\n",
    "pred_ssk = bestSskModel.predict(ssk_gram)\n",
    "pred_ngk = bestNgKModel.predict(ngk_gram)\n",
    "\n",
    "#we will create the confusion matrix from these results\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "cnf_matrix_ssk = confusion_matrix(true, pred_ssk)\n",
    "cnf_matrix_ngk = confusion_matrix(true, pred_ngk)\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix_ssk, classes=(\"English\",\"Spanish\"),\n",
    "                      title='Using SSK')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix_ngk, classes=(\"English\",\"Spanish\"),\n",
    "                      title='Using NGK')\n",
    "\n",
    "plt.show()\n",
    "# Compute confusion matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english words classified as spanish:  ['club', 'alive', 'mama', 'camera', 'information', 'travel', 'final', 'horrible', 'involve', 'uncomfortable', 'entrance', 'extra', 'create', 'charge', 'record', 'cigarette', 'restaurant', 'mistake', 'exit', 'alarm']\n",
      "spanish words classified as english:  ['flores', 'zona', 'henry', 'jimmy', 'johnny', 'peter', 'color', 'azul', 'miles', 'juez', 'ingles', 'rojo', 'isla', 'luces', 'esperen', 'come', 'sepa', 'nota', 'nave', 'base']\n"
     ]
    }
   ],
   "source": [
    "bad_eng = []\n",
    "bad_esp = []\n",
    "\n",
    "for i in range(len(prod)):\n",
    "    if true[i] != pred_ssk[i]:\n",
    "        if true[i] == 0:\n",
    "            bad_eng.append(prod[i])\n",
    "        else:\n",
    "            bad_esp.append(prod[i])\n",
    "            \n",
    "print \"english words classified as spanish: \" , bad_eng[:20]\n",
    "print \"spanish words classified as english: \" , bad_esp[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple possible explanations for the missclasifications:\n",
    "    \n",
    "* There are shared words between english and spanish e.g. extra, come, miles, final, horrible, base, etc.\n",
    "* There are proper names in the datasets e.g. Henry, Jimmy, Johnny, etc.\n",
    "* There are some substrings of the words that belong to the other lanaguage e.g. **is**la, **not**a, **crea**te, etc.\n",
    "\n",
    "#### (iii)\n",
    "\n",
    "* Finding the gram matrix for SSK is very compute intensive and since we obtained comparable results using NGK is probably not a good kernel for language classification.\n",
    "* We obtained the best results for SSK with $\\lambda = 0.75, n = 3$ and $C = 1$. Further grid exploration of $\\lambda$ and $C$ around these values would be worthy.\n",
    "* For a bag of words with average length equals to 5 we obtained the best results for $n = 3$ for SSK and $n=2$ for NGK it means that when using substrings kernels like the ones used here, it is not a good idea to start with the average as an estimator of the optimal value of n.\n",
    "* There would be better results if we previously avoid the \"undecidable\" cases e.g. club, come, miles, etc. And the proper names e.g. Henry, Jimmy, etc. \n",
    "\n",
    "### References\n",
    "\n",
    "##### [1] V. Polianskii, B. Godefroy, W. Kryscinski, F. Franzen (2017). Re-implementation and analysis of the \"Text Classification using String Kernels\" paper, by Lodhi, Saunders, Shawe-Taylor, Cristianini and Watkins. Report of Project\n",
    "##### [2]  Lodhi, H., Saunders, C., Shawe-Taylor, J., Cristianini, N., & Watkins, C. (2002). Text classification using string kernels. Journal of Machine Learning Research, 2(Feb), 419-444"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
